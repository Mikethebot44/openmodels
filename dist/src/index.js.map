{"version":3,"sources":["../../src/index.ts","../../src/providers/huggingface.ts","../../src/streaming.ts","../../src/registry.ts","../../src/client.ts","../../src/model-capabilities.ts"],"sourcesContent":["export { OpenModels, client } from './client';\r\nexport { parseSSEStream, OpenModelsError } from './streaming';\r\nexport { getModelCapabilities, type ModelCapabilities } from './model-capabilities';\r\nexport * from './types';\r\n\r\n","import { HfInference } from '@huggingface/inference';\r\nimport {\r\n  ChatCompletionRequest,\r\n  EmbeddingRequest,\r\n  ImageRequest,\r\n  AudioTranscribeRequest,\r\n  ImageClassificationRequest\r\n} from '../types';\r\n\r\nexport class HuggingFaceProvider {\r\n  private hf: HfInference;\r\n  private apiKey: string;\r\n\r\n  constructor(config: { apiKey: string; hfToken?: string }) {\r\n    this.apiKey = config.apiKey;\r\n    // Use HF token if provided, otherwise use the OpenModels API key\r\n    const token = config.hfToken || process.env.HF_TOKEN;\r\n    if (!token) {\r\n      throw new Error('HuggingFace token is required');\r\n    }\r\n    this.hf = new HfInference(token);\r\n  }\r\n\r\n  async chat(request: ChatCompletionRequest): Promise<Response> {\r\n    const response = await this.hf.chatCompletion({\r\n      model: request.model,\r\n      messages: request.messages,\r\n      temperature: request.temperature,\r\n      max_tokens: request.max_tokens,\r\n      top_p: request.top_p,\r\n      stop: request.stop,\r\n      stream: request.stream || false,\r\n    });\r\n\r\n    // Convert HF response to OpenModels format\r\n    return new Response(JSON.stringify({\r\n      id: `chatcmpl-${Date.now()}`,\r\n      object: 'chat.completion',\r\n      model: request.model,\r\n      choices: [{\r\n        message: {\r\n          role: 'assistant',\r\n          content: response.choices[0].message.content\r\n        },\r\n        finish_reason: response.choices[0].finish_reason\r\n      }],\r\n      usage: response.usage\r\n    }));\r\n  }\r\n\r\n  async embed(request: EmbeddingRequest): Promise<Response> {\r\n    const response = await this.hf.featureExtraction({\r\n      model: request.model,\r\n      inputs: Array.isArray(request.input) ? request.input : [request.input]\r\n    });\r\n\r\n    return new Response(JSON.stringify({\r\n      object: 'list',\r\n      data: Array.isArray(response[0]) ? response.map((embedding, i) => ({\r\n        object: 'embedding',\r\n        embedding: embedding,\r\n        index: i\r\n      })) : [{\r\n        object: 'embedding',\r\n        embedding: response,\r\n        index: 0\r\n      }],\r\n      model: request.model\r\n    }));\r\n  }\r\n\r\n  async image(request: ImageRequest): Promise<Response> {\r\n    const response = await this.hf.textToImage({\r\n      model: request.model,\r\n      inputs: request.prompt,\r\n      parameters: {\r\n        width: parseInt(request.size?.split('x')[0] || '1024'),\r\n        height: parseInt(request.size?.split('x')[1] || '1024'),\r\n        num_inference_steps: request.quality === 'hd' ? 50 : 25\r\n      }\r\n    });\r\n\r\n    // Convert blob to base64\r\n    const buffer = await response.arrayBuffer();\r\n    const base64 = Buffer.from(buffer).toString('base64');\r\n\r\n    return new Response(JSON.stringify({\r\n      data: [{\r\n        b64_json: base64\r\n      }]\r\n    }));\r\n  }\r\n\r\n  async audioTranscribe(request: AudioTranscribeRequest): Promise<Response> {\r\n    // Fetch audio file if URL provided\r\n    const audioBlob = await fetch(request.input).then(r => r.blob());\r\n    \r\n    const response = await this.hf.automaticSpeechRecognition({\r\n      model: request.model,\r\n      data: audioBlob\r\n    });\r\n\r\n    return new Response(JSON.stringify({\r\n      text: response.text\r\n    }));\r\n  }\r\n\r\n  async audioSummarize(request: any): Promise<Response> {\r\n    // First transcribe the audio\r\n    const audioBlob = await fetch(request.input).then(r => r.blob());\r\n    \r\n    const transcription = await this.hf.automaticSpeechRecognition({\r\n      model: request.model || 'openai/whisper-base',\r\n      data: audioBlob\r\n    });\r\n\r\n    // Then summarize the text using a summarization model\r\n    const summary = await this.hf.summarization({\r\n      model: 'facebook/bart-large-cnn',\r\n      inputs: transcription.text,\r\n      parameters: {\r\n        max_length: 150,\r\n        min_length: 30\r\n      }\r\n    });\r\n\r\n    return new Response(JSON.stringify({\r\n      text: summary.summary_text\r\n    }));\r\n  }\r\n\r\n  async visionClassify(request: ImageClassificationRequest): Promise<Response> {\r\n    // Fetch image if URL provided\r\n    const imageBlob = await fetch(request.input).then(r => r.blob());\r\n    \r\n    const response = await this.hf.imageClassification({\r\n      model: request.model,\r\n      data: imageBlob\r\n    });\r\n\r\n    return new Response(JSON.stringify({\r\n      classifications: response.map(r => ({\r\n        label: r.label,\r\n        score: r.score\r\n      }))\r\n    }));\r\n  }\r\n}\r\n\r\n","import { StreamChunk } from './types';\n\nexport class OpenModelsError extends Error {\n  constructor(\n    message: string,\n    public status?: number,\n    public code?: string\n  ) {\n    super(message);\n    this.name = 'OpenModelsError';\n  }\n}\n\nexport async function* parseSSEStream(\n  response: any\n): AsyncGenerator<string, void, unknown> {\n  if (!response.body) {\n    throw new OpenModelsError('Response body is null');\n  }\n\n  // Handle authentication errors before parsing stream\n  if (response.status === 401) {\n    throw new OpenModelsError('Invalid API key. Please check your credentials.', 401);\n  }\n  if (response.status === 403) {\n    throw new OpenModelsError('Insufficient credits. Please top up your account.', 403);\n  }\n\n  // Handle node-fetch response\n  const text = await response.text();\n  const lines = text.split('\\n');\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n    \n    if (trimmed === '') continue;\n    if (trimmed === '[DONE]') return;\n    \n    if (trimmed.startsWith('data: ')) {\n      const data = trimmed.slice(6);\n      if (data === '[DONE]') return;\n      \n      try {\n        const parsed: StreamChunk = JSON.parse(data);\n        if (parsed.choices?.[0]?.delta?.content) {\n          yield parsed.choices[0].delta.content;\n        }\n      } catch (e) {\n        // Skip malformed JSON\n        continue;\n      }\n    }\n  }\n}\n","import { Task } from './types/run';\r\n\r\nexport const TASK_TO_MODELS: Record<Task, string[]> = {\r\n  'image-classification': [\r\n    'google/vit-base-patch16-224',\r\n    'facebook/convnext-base-224',\r\n    'openai/clip-vit-base-patch32',\r\n  ],\r\n  'text-generation': [\r\n    'microsoft/DialoGPT-medium',\r\n    'meta-llama/Llama-3.1-8B-Instruct',\r\n    'meta-llama/Meta-Llama-3-8B-Instruct',\r\n  ],\r\n  'embedding': [\r\n    'sentence-transformers/all-MiniLM-L6-v2',\r\n  ],\r\n  'audio-transcribe': [\r\n    'openai/whisper-base',\r\n  ],\r\n  'audio-summarize': [\r\n    'facebook/bart-large-cnn',\r\n  ],\r\n  'image-generation': [\r\n    'runwayml/stable-diffusion-v1-5',\r\n  ],\r\n};\r\n\r\nexport function getDefaultModel(task: Task): string {\r\n  const models = TASK_TO_MODELS[task];\r\n  if (!models || models.length === 0) {\r\n    throw new Error(`No default models configured for task: ${task}`);\r\n  }\r\n  return models[0];\r\n}\r\n\r\n\r\n","import { HuggingFaceProvider } from './providers/huggingface';\r\nimport { parseSSEStream, OpenModelsError } from './streaming';\r\nimport { \r\n  OpenModelsConfig, \r\n  ChatCompletionRequest, \r\n  ChatCompletionResponse,\r\n  EmbeddingRequest,\r\n  EmbeddingResponse,\r\n  ImageRequest,\r\n  ImageResponse,\r\n  AudioTranscribeRequest,\r\n  AudioTranscribeResponse,\r\n  AudioSummarizeRequest,\r\n  AudioSummarizeResponse,\r\n  ImageClassificationRequest,\r\n  ImageClassificationResponse,\r\n  RunRequest,\r\n  RunResponse\r\n} from './types';\r\nimport { getDefaultModel } from './registry';\r\n\r\nexport class OpenModels {\r\n  private textProvider: HuggingFaceProvider;\r\n  private embedProvider: HuggingFaceProvider;\r\n  private imageProvider: HuggingFaceProvider;\r\n  private audioProvider: HuggingFaceProvider;\r\n  private visionProvider: HuggingFaceProvider;\r\n\r\n  constructor(config: OpenModelsConfig = {}) {\r\n    // Validate that API key is provided\r\n    if (!config.apiKey) {\r\n      throw new OpenModelsError('API key is required. Please provide an API key in the client configuration.');\r\n    }\r\n\r\n    // Validate API key format\r\n    if (!config.apiKey.startsWith('om_') || config.apiKey.length < 10) {\r\n      throw new OpenModelsError('Invalid API key format. API keys must start with \"om_\" and be at least 10 characters long.');\r\n    }\r\n\r\n    // Use HuggingFace Inference Providers\r\n    const hfConfig = { \r\n      apiKey: config.apiKey,\r\n      hfToken: config.hfToken \r\n    };\r\n    \r\n    this.textProvider = new HuggingFaceProvider(hfConfig);\r\n    this.embedProvider = new HuggingFaceProvider(hfConfig);\r\n    this.imageProvider = new HuggingFaceProvider(hfConfig);\r\n    this.audioProvider = new HuggingFaceProvider(hfConfig);\r\n    this.visionProvider = new HuggingFaceProvider(hfConfig);\r\n  }\r\n\r\n  async chat(request: ChatCompletionRequest): Promise<ChatCompletionResponse | AsyncGenerator<string, void, unknown>> {\r\n    try {\r\n      const response = await this.textProvider.chat(request);\r\n      \r\n      if (request.stream) {\r\n        return parseSSEStream(response);\r\n      }\r\n      \r\n      const data = await response.json();\r\n      return data as ChatCompletionResponse;\r\n    } catch (error) {\r\n      if (error instanceof Error) {\r\n        throw new OpenModelsError(error.message);\r\n      }\r\n      throw new OpenModelsError('Unknown error occurred');\r\n    }\r\n  }\r\n\r\n  async embed(request: EmbeddingRequest): Promise<EmbeddingResponse> {\r\n    try {\r\n      const response = await this.embedProvider.embed(request);\r\n      const data = await response.json();\r\n      return data as EmbeddingResponse;\r\n    } catch (error) {\r\n      if (error instanceof Error) {\r\n        throw new OpenModelsError(error.message);\r\n      }\r\n      throw new OpenModelsError('Unknown error occurred');\r\n    }\r\n  }\r\n\r\n  async image(request: ImageRequest): Promise<ImageResponse> {\r\n    try {\r\n      const response = await this.imageProvider.image(request);\r\n      const data = await response.json();\r\n      return data as ImageResponse;\r\n    } catch (error) {\r\n      if (error instanceof Error) {\r\n        throw new OpenModelsError(error.message);\r\n      }\r\n      throw new OpenModelsError('Unknown error occurred');\r\n    }\r\n  }\r\n\r\n  async run(request: RunRequest): Promise<RunResponse | AsyncGenerator<string, void, unknown>> {\r\n    try {\r\n      switch (request.task) {\r\n        case 'text-generation': {\r\n          const model = (request as any).model || getDefaultModel('text-generation');\r\n          const chatReq: ChatCompletionRequest = { ...request, model } as any;\r\n          const response = await this.textProvider.chat(chatReq);\r\n          if (chatReq.stream) return parseSSEStream(response);\r\n          return (await response.json()) as ChatCompletionResponse;\r\n        }\r\n        case 'image-generation': {\r\n          const model = (request as any).model || getDefaultModel('image-generation');\r\n          const imgReq: ImageRequest = { ...request, model } as any;\r\n          const response = await this.imageProvider.image(imgReq);\r\n          return (await response.json()) as ImageResponse;\r\n        }\r\n        case 'embedding': {\r\n          const model = (request as any).model || getDefaultModel('embedding');\r\n          const embReq: EmbeddingRequest = { ...request, model } as any;\r\n          const response = await this.embedProvider.embed(embReq);\r\n          return (await response.json()) as any;\r\n        }\r\n        case 'audio-transcribe': {\r\n          const model = (request as any).model || getDefaultModel('audio-transcribe');\r\n          const aReq: AudioTranscribeRequest = { ...request, model } as any;\r\n          const response = await this.audioProvider.audioTranscribe!(aReq);\r\n          return (await response.json()) as AudioTranscribeResponse;\r\n        }\r\n        case 'audio-summarize': {\r\n          const model = (request as any).model || getDefaultModel('audio-summarize');\r\n          const aReq: AudioSummarizeRequest = { ...request, model } as any;\r\n          const response = await this.audioProvider.audioSummarize!(aReq);\r\n          return (await response.json()) as AudioSummarizeResponse;\r\n        }\r\n        case 'image-classification': {\r\n          const model = (request as any).model || getDefaultModel('image-classification');\r\n          const vReq: ImageClassificationRequest = { ...request, model } as any;\r\n          const response = await this.visionProvider.visionClassify!(vReq);\r\n          return (await response.json()) as ImageClassificationResponse;\r\n        }\r\n        default:\r\n          throw new OpenModelsError('Unsupported task');\r\n      }\r\n    } catch (error) {\r\n      if (error instanceof Error) throw new OpenModelsError(error.message);\r\n      throw new OpenModelsError('Unknown error occurred');\r\n    }\r\n  }\r\n}\r\n\r\nexport function client(config?: OpenModelsConfig): OpenModels {\r\n  return new OpenModels(config);\r\n}\r\n\r\n","export interface ModelCapabilities {\r\n  supportsTopP: boolean;\r\n  supportsStop: boolean;\r\n  supportsTemperature: boolean;\r\n  supportsMaxTokens: boolean;\r\n  supportsStreaming: boolean;\r\n  supportsQuantization: boolean;\r\n  supportedQuantizations?: ('int8' | 'int4' | 'float16')[];\r\n  maxTokenLimit?: number;\r\n  notes?: string;\r\n}\r\n\r\nexport const TEXT_MODEL_CAPABILITIES: Record<string, ModelCapabilities> = {\r\n  \"microsoft/DialoGPT-medium\": {\r\n    supportsTopP: true,\r\n    supportsStop: true,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    maxTokenLimit: 1000,\r\n    notes: \"Conversational model, best for dialog\"\r\n  },\r\n  \"microsoft/DialoGPT-large\": {\r\n    supportsTopP: true,\r\n    supportsStop: true,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    maxTokenLimit: 1000\r\n  },\r\n  \"meta-llama/Llama-3.1-8B-Instruct\": {\r\n    supportsTopP: true,\r\n    supportsStop: true,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'int4', 'float16'],\r\n    maxTokenLimit: 4096,\r\n    notes: \"Instruction-following model\"\r\n  },\r\n  \"meta-llama/Meta-Llama-3-8B-Instruct\": {\r\n    supportsTopP: true,\r\n    supportsStop: true,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'int4', 'float16'],\r\n    maxTokenLimit: 4096,\r\n    notes: \"Instruction-following model with chat formatting\"\r\n  },\r\n  \"facebook/blenderbot-400M-distill\": {\r\n    supportsTopP: true,\r\n    supportsStop: false,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    maxTokenLimit: 128\r\n  },\r\n  \"EleutherAI/gpt-neo-2.7B\": {\r\n    supportsTopP: true,\r\n    supportsStop: true,\r\n    supportsTemperature: true,\r\n    supportsMaxTokens: true,\r\n    supportsStreaming: true,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'int4', 'float16'],\r\n    maxTokenLimit: 2048\r\n  }\r\n};\r\n\r\nexport const IMAGE_MODEL_CAPABILITIES: Record<string, ModelCapabilities> = {\r\n  \"runwayml/stable-diffusion-v1-5\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['float16'],\r\n    notes: \"Size, quality, style parameters supported\"\r\n  },\r\n  \"stabilityai/stable-diffusion-xl-base-1.0\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['float16'],\r\n    notes: \"Higher quality, slower generation\"\r\n  }\r\n};\r\n\r\nexport const EMBED_MODEL_CAPABILITIES: Record<string, ModelCapabilities> = {\r\n  \"sentence-transformers/all-MiniLM-L6-v2\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: false,\r\n    notes: \"Fast and efficient, good for most tasks\"\r\n  }\r\n};\r\n\r\nexport const VISION_MODEL_CAPABILITIES: Record<string, ModelCapabilities> = {\r\n  \"google/vit-base-patch16-224\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    notes: \"Vision Transformer, good balance\"\r\n  },\r\n  \"facebook/convnext-base-224\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16']\r\n  },\r\n  \"openai/clip-vit-base-patch32\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16']\r\n  }\r\n};\r\n\r\nexport const AUDIO_MODEL_CAPABILITIES: Record<string, ModelCapabilities> = {\r\n  \"openai/whisper-base\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    notes: \"Fast, good for most languages\"\r\n  },\r\n  \"openai/whisper-small\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    notes: \"Better accuracy than base\"\r\n  },\r\n  \"openai/whisper-medium\": {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: true,\r\n    supportedQuantizations: ['int8', 'float16'],\r\n    notes: \"High accuracy, slower\"\r\n  }\r\n};\r\n\r\nexport function getModelCapabilities(model: string, type: 'text' | 'image' | 'embed' | 'vision' | 'audio'): ModelCapabilities {\r\n  const defaultCapabilities: ModelCapabilities = {\r\n    supportsTopP: false,\r\n    supportsStop: false,\r\n    supportsTemperature: false,\r\n    supportsMaxTokens: false,\r\n    supportsStreaming: false,\r\n    supportsQuantization: false\r\n  };\r\n\r\n  let registry: Record<string, ModelCapabilities>;\r\n  switch (type) {\r\n    case 'text': registry = TEXT_MODEL_CAPABILITIES; break;\r\n    case 'image': registry = IMAGE_MODEL_CAPABILITIES; break;\r\n    case 'embed': registry = EMBED_MODEL_CAPABILITIES; break;\r\n    case 'vision': registry = VISION_MODEL_CAPABILITIES; break;\r\n    case 'audio': registry = AUDIO_MODEL_CAPABILITIES; break;\r\n    default: return defaultCapabilities;\r\n  }\r\n\r\n  return registry[model] || defaultCapabilities;\r\n}\r\n\r\n"],"mappings":"yaAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,gBAAAE,EAAA,oBAAAC,EAAA,WAAAC,EAAA,yBAAAC,EAAA,mBAAAC,IAAA,eAAAC,EAAAP,GCAA,IAAAQ,EAA4B,kCASfC,EAAN,KAA0B,CAI/B,YAAYC,EAA8C,CACxD,KAAK,OAASA,EAAO,OAErB,IAAMC,EAAQD,EAAO,SAAW,QAAQ,IAAI,SAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+BAA+B,EAEjD,KAAK,GAAK,IAAI,cAAYA,CAAK,CACjC,CAEA,MAAM,KAAKC,EAAmD,CAC5D,IAAMC,EAAW,MAAM,KAAK,GAAG,eAAe,CAC5C,MAAOD,EAAQ,MACf,SAAUA,EAAQ,SAClB,YAAaA,EAAQ,YACrB,WAAYA,EAAQ,WACpB,MAAOA,EAAQ,MACf,KAAMA,EAAQ,KACd,OAAQA,EAAQ,QAAU,EAC5B,CAAC,EAGD,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,GAAI,YAAY,KAAK,IAAI,CAAC,GAC1B,OAAQ,kBACR,MAAOA,EAAQ,MACf,QAAS,CAAC,CACR,QAAS,CACP,KAAM,YACN,QAASC,EAAS,QAAQ,CAAC,EAAE,QAAQ,OACvC,EACA,cAAeA,EAAS,QAAQ,CAAC,EAAE,aACrC,CAAC,EACD,MAAOA,EAAS,KAClB,CAAC,CAAC,CACJ,CAEA,MAAM,MAAMD,EAA8C,CACxD,IAAMC,EAAW,MAAM,KAAK,GAAG,kBAAkB,CAC/C,MAAOD,EAAQ,MACf,OAAQ,MAAM,QAAQA,EAAQ,KAAK,EAAIA,EAAQ,MAAQ,CAACA,EAAQ,KAAK,CACvE,CAAC,EAED,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,OAAQ,OACR,KAAM,MAAM,QAAQC,EAAS,CAAC,CAAC,EAAIA,EAAS,IAAI,CAACC,EAAWC,KAAO,CACjE,OAAQ,YACR,UAAWD,EACX,MAAOC,CACT,EAAE,EAAI,CAAC,CACL,OAAQ,YACR,UAAWF,EACX,MAAO,CACT,CAAC,EACD,MAAOD,EAAQ,KACjB,CAAC,CAAC,CACJ,CAEA,MAAM,MAAMA,EAA0C,CAYpD,IAAMI,EAAS,MAXE,MAAM,KAAK,GAAG,YAAY,CACzC,MAAOJ,EAAQ,MACf,OAAQA,EAAQ,OAChB,WAAY,CACV,MAAO,SAASA,EAAQ,MAAM,MAAM,GAAG,EAAE,CAAC,GAAK,MAAM,EACrD,OAAQ,SAASA,EAAQ,MAAM,MAAM,GAAG,EAAE,CAAC,GAAK,MAAM,EACtD,oBAAqBA,EAAQ,UAAY,KAAO,GAAK,EACvD,CACF,CAAC,GAG6B,YAAY,EACpCK,EAAS,OAAO,KAAKD,CAAM,EAAE,SAAS,QAAQ,EAEpD,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,KAAM,CAAC,CACL,SAAUC,CACZ,CAAC,CACH,CAAC,CAAC,CACJ,CAEA,MAAM,gBAAgBL,EAAoD,CAExE,IAAMM,EAAY,MAAM,MAAMN,EAAQ,KAAK,EAAE,KAAKO,GAAKA,EAAE,KAAK,CAAC,EAEzDN,EAAW,MAAM,KAAK,GAAG,2BAA2B,CACxD,MAAOD,EAAQ,MACf,KAAMM,CACR,CAAC,EAED,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,KAAML,EAAS,IACjB,CAAC,CAAC,CACJ,CAEA,MAAM,eAAeD,EAAiC,CAEpD,IAAMM,EAAY,MAAM,MAAMN,EAAQ,KAAK,EAAE,KAAKO,GAAKA,EAAE,KAAK,CAAC,EAEzDC,EAAgB,MAAM,KAAK,GAAG,2BAA2B,CAC7D,MAAOR,EAAQ,OAAS,sBACxB,KAAMM,CACR,CAAC,EAGKG,EAAU,MAAM,KAAK,GAAG,cAAc,CAC1C,MAAO,0BACP,OAAQD,EAAc,KACtB,WAAY,CACV,WAAY,IACZ,WAAY,EACd,CACF,CAAC,EAED,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,KAAMC,EAAQ,YAChB,CAAC,CAAC,CACJ,CAEA,MAAM,eAAeT,EAAwD,CAE3E,IAAMU,EAAY,MAAM,MAAMV,EAAQ,KAAK,EAAE,KAAKO,GAAKA,EAAE,KAAK,CAAC,EAEzDN,EAAW,MAAM,KAAK,GAAG,oBAAoB,CACjD,MAAOD,EAAQ,MACf,KAAMU,CACR,CAAC,EAED,OAAO,IAAI,SAAS,KAAK,UAAU,CACjC,gBAAiBT,EAAS,IAAIM,IAAM,CAClC,MAAOA,EAAE,MACT,MAAOA,EAAE,KACX,EAAE,CACJ,CAAC,CAAC,CACJ,CACF,ECjJO,IAAMI,EAAN,cAA8B,KAAM,CACzC,YACEC,EACOC,EACAC,EACP,CACA,MAAMF,CAAO,EAHN,YAAAC,EACA,UAAAC,EAGP,KAAK,KAAO,iBACd,CACF,EAEA,eAAuBC,EACrBC,EACuC,CACvC,GAAI,CAACA,EAAS,KACZ,MAAM,IAAIL,EAAgB,uBAAuB,EAInD,GAAIK,EAAS,SAAW,IACtB,MAAM,IAAIL,EAAgB,kDAAmD,GAAG,EAElF,GAAIK,EAAS,SAAW,IACtB,MAAM,IAAIL,EAAgB,oDAAqD,GAAG,EAKpF,IAAMM,GADO,MAAMD,EAAS,KAAK,GACd,MAAM;AAAA,CAAI,EAE7B,QAAWE,KAAQD,EAAO,CACxB,IAAME,EAAUD,EAAK,KAAK,EAE1B,GAAIC,IAAY,GAChB,IAAIA,IAAY,SAAU,OAE1B,GAAIA,EAAQ,WAAW,QAAQ,EAAG,CAChC,IAAMC,EAAOD,EAAQ,MAAM,CAAC,EAC5B,GAAIC,IAAS,SAAU,OAEvB,GAAI,CACF,IAAMC,EAAsB,KAAK,MAAMD,CAAI,EACvCC,EAAO,UAAU,CAAC,GAAG,OAAO,UAC9B,MAAMA,EAAO,QAAQ,CAAC,EAAE,MAAM,QAElC,MAAY,CAEV,QACF,CACF,EACF,CACF,CCnDO,IAAMC,EAAyC,CACpD,uBAAwB,CACtB,8BACA,6BACA,8BACF,EACA,kBAAmB,CACjB,4BACA,mCACA,qCACF,EACA,UAAa,CACX,wCACF,EACA,mBAAoB,CAClB,qBACF,EACA,kBAAmB,CACjB,yBACF,EACA,mBAAoB,CAClB,gCACF,CACF,EAEO,SAASC,EAAgBC,EAAoB,CAClD,IAAMC,EAASH,EAAeE,CAAI,EAClC,GAAI,CAACC,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0CAA0CD,CAAI,EAAE,EAElE,OAAOC,EAAO,CAAC,CACjB,CCZO,IAAMC,EAAN,KAAiB,CAOtB,YAAYC,EAA2B,CAAC,EAAG,CAEzC,GAAI,CAACA,EAAO,OACV,MAAM,IAAIC,EAAgB,6EAA6E,EAIzG,GAAI,CAACD,EAAO,OAAO,WAAW,KAAK,GAAKA,EAAO,OAAO,OAAS,GAC7D,MAAM,IAAIC,EAAgB,4FAA4F,EAIxH,IAAMC,EAAW,CACf,OAAQF,EAAO,OACf,QAASA,EAAO,OAClB,EAEA,KAAK,aAAe,IAAIG,EAAoBD,CAAQ,EACpD,KAAK,cAAgB,IAAIC,EAAoBD,CAAQ,EACrD,KAAK,cAAgB,IAAIC,EAAoBD,CAAQ,EACrD,KAAK,cAAgB,IAAIC,EAAoBD,CAAQ,EACrD,KAAK,eAAiB,IAAIC,EAAoBD,CAAQ,CACxD,CAEA,MAAM,KAAKE,EAAyG,CAClH,GAAI,CACF,IAAMC,EAAW,MAAM,KAAK,aAAa,KAAKD,CAAO,EAErD,OAAIA,EAAQ,OACHE,EAAeD,CAAQ,EAGnB,MAAMA,EAAS,KAAK,CAEnC,OAASE,EAAO,CACd,MAAIA,aAAiB,MACb,IAAIN,EAAgBM,EAAM,OAAO,EAEnC,IAAIN,EAAgB,wBAAwB,CACpD,CACF,CAEA,MAAM,MAAMG,EAAuD,CACjE,GAAI,CAGF,OADa,MADI,MAAM,KAAK,cAAc,MAAMA,CAAO,GAC3B,KAAK,CAEnC,OAASG,EAAO,CACd,MAAIA,aAAiB,MACb,IAAIN,EAAgBM,EAAM,OAAO,EAEnC,IAAIN,EAAgB,wBAAwB,CACpD,CACF,CAEA,MAAM,MAAMG,EAA+C,CACzD,GAAI,CAGF,OADa,MADI,MAAM,KAAK,cAAc,MAAMA,CAAO,GAC3B,KAAK,CAEnC,OAASG,EAAO,CACd,MAAIA,aAAiB,MACb,IAAIN,EAAgBM,EAAM,OAAO,EAEnC,IAAIN,EAAgB,wBAAwB,CACpD,CACF,CAEA,MAAM,IAAIG,EAAmF,CAC3F,GAAI,CACF,OAAQA,EAAQ,KAAM,CACpB,IAAK,kBAAmB,CACtB,IAAMI,EAASJ,EAAgB,OAASK,EAAgB,iBAAiB,EACnEC,EAAiC,CAAE,GAAGN,EAAS,MAAAI,CAAM,EACrDH,EAAW,MAAM,KAAK,aAAa,KAAKK,CAAO,EACrD,OAAIA,EAAQ,OAAeJ,EAAeD,CAAQ,EAC1C,MAAMA,EAAS,KAAK,CAC9B,CACA,IAAK,mBAAoB,CACvB,IAAMG,EAASJ,EAAgB,OAASK,EAAgB,kBAAkB,EACpEE,EAAuB,CAAE,GAAGP,EAAS,MAAAI,CAAM,EAEjD,OAAQ,MADS,MAAM,KAAK,cAAc,MAAMG,CAAM,GAC/B,KAAK,CAC9B,CACA,IAAK,YAAa,CAChB,IAAMH,EAASJ,EAAgB,OAASK,EAAgB,WAAW,EAC7DG,EAA2B,CAAE,GAAGR,EAAS,MAAAI,CAAM,EAErD,OAAQ,MADS,MAAM,KAAK,cAAc,MAAMI,CAAM,GAC/B,KAAK,CAC9B,CACA,IAAK,mBAAoB,CACvB,IAAMJ,EAASJ,EAAgB,OAASK,EAAgB,kBAAkB,EACpEI,EAA+B,CAAE,GAAGT,EAAS,MAAAI,CAAM,EAEzD,OAAQ,MADS,MAAM,KAAK,cAAc,gBAAiBK,CAAI,GACxC,KAAK,CAC9B,CACA,IAAK,kBAAmB,CACtB,IAAML,EAASJ,EAAgB,OAASK,EAAgB,iBAAiB,EACnEI,EAA8B,CAAE,GAAGT,EAAS,MAAAI,CAAM,EAExD,OAAQ,MADS,MAAM,KAAK,cAAc,eAAgBK,CAAI,GACvC,KAAK,CAC9B,CACA,IAAK,uBAAwB,CAC3B,IAAML,EAASJ,EAAgB,OAASK,EAAgB,sBAAsB,EACxEK,EAAmC,CAAE,GAAGV,EAAS,MAAAI,CAAM,EAE7D,OAAQ,MADS,MAAM,KAAK,eAAe,eAAgBM,CAAI,GACxC,KAAK,CAC9B,CACA,QACE,MAAM,IAAIb,EAAgB,kBAAkB,CAChD,CACF,OAASM,EAAO,CACd,MAAIA,aAAiB,MAAa,IAAIN,EAAgBM,EAAM,OAAO,EAC7D,IAAIN,EAAgB,wBAAwB,CACpD,CACF,CACF,EAEO,SAASc,EAAOf,EAAuC,CAC5D,OAAO,IAAID,EAAWC,CAAM,CAC9B,CCxIO,IAAMgB,EAA6D,CACxE,4BAA6B,CAC3B,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,cAAe,IACf,MAAO,uCACT,EACA,2BAA4B,CAC1B,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,cAAe,GACjB,EACA,mCAAoC,CAClC,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,OAAQ,SAAS,EAClD,cAAe,KACf,MAAO,6BACT,EACA,sCAAuC,CACrC,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,OAAQ,SAAS,EAClD,cAAe,KACf,MAAO,kDACT,EACA,mCAAoC,CAClC,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,cAAe,GACjB,EACA,0BAA2B,CACzB,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,OAAQ,SAAS,EAClD,cAAe,IACjB,CACF,EAEaC,EAA8D,CACzE,iCAAkC,CAChC,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,SAAS,EAClC,MAAO,2CACT,EACA,2CAA4C,CAC1C,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,SAAS,EAClC,MAAO,mCACT,CACF,EAEaC,EAA8D,CACzE,yCAA0C,CACxC,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,MAAO,yCACT,CACF,EAEaC,EAA+D,CAC1E,8BAA+B,CAC7B,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,MAAO,kCACT,EACA,6BAA8B,CAC5B,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,CAC5C,EACA,+BAAgC,CAC9B,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,CAC5C,CACF,EAEaC,EAA8D,CACzE,sBAAuB,CACrB,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,MAAO,+BACT,EACA,uBAAwB,CACtB,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,MAAO,2BACT,EACA,wBAAyB,CACvB,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,GACtB,uBAAwB,CAAC,OAAQ,SAAS,EAC1C,MAAO,uBACT,CACF,EAEO,SAASC,EAAqBC,EAAeC,EAA0E,CAC5H,IAAMC,EAAyC,CAC7C,aAAc,GACd,aAAc,GACd,oBAAqB,GACrB,kBAAmB,GACnB,kBAAmB,GACnB,qBAAsB,EACxB,EAEIC,EACJ,OAAQF,EAAM,CACZ,IAAK,OAAQE,EAAWT,EAAyB,MACjD,IAAK,QAASS,EAAWR,EAA0B,MACnD,IAAK,QAASQ,EAAWP,EAA0B,MACnD,IAAK,SAAUO,EAAWN,EAA2B,MACrD,IAAK,QAASM,EAAWL,EAA0B,MACnD,QAAS,OAAOI,CAClB,CAEA,OAAOC,EAASH,CAAK,GAAKE,CAC5B","names":["src_exports","__export","OpenModels","OpenModelsError","client","getModelCapabilities","parseSSEStream","__toCommonJS","import_inference","HuggingFaceProvider","config","token","request","response","embedding","i","buffer","base64","audioBlob","r","transcription","summary","imageBlob","OpenModelsError","message","status","code","parseSSEStream","response","lines","line","trimmed","data","parsed","TASK_TO_MODELS","getDefaultModel","task","models","OpenModels","config","OpenModelsError","hfConfig","HuggingFaceProvider","request","response","parseSSEStream","error","model","getDefaultModel","chatReq","imgReq","embReq","aReq","vReq","client","TEXT_MODEL_CAPABILITIES","IMAGE_MODEL_CAPABILITIES","EMBED_MODEL_CAPABILITIES","VISION_MODEL_CAPABILITIES","AUDIO_MODEL_CAPABILITIES","getModelCapabilities","model","type","defaultCapabilities","registry"]}