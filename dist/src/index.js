"use strict";var c=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var b=Object.getOwnPropertyNames;var w=Object.prototype.hasOwnProperty;var T=(a,e)=>{for(var t in e)c(a,t,{get:e[t],enumerable:!0})},x=(a,e,t,s)=>{if(e&&typeof e=="object"||typeof e=="function")for(let o of b(e))!w.call(a,o)&&o!==t&&c(a,o,{get:()=>e[o],enumerable:!(s=h(e,o))||s.enumerable});return a};var y=a=>x(c({},"__esModule",{value:!0}),a);var C={};T(C,{OpenModels:()=>u,OpenModelsError:()=>r,client:()=>f,getModelCapabilities:()=>g,parseSSEStream:()=>p});module.exports=y(C);var d=require("@huggingface/inference"),n=class{constructor(e){this.apiKey=e.apiKey;let t=e.hfToken||process.env.HF_TOKEN;if(!t)throw new Error("HuggingFace token is required");this.hf=new d.HfInference(t)}async chat(e){let t=await this.hf.chatCompletion({model:e.model,messages:e.messages,temperature:e.temperature,max_tokens:e.max_tokens,top_p:e.top_p,stop:e.stop,stream:e.stream||!1});return new Response(JSON.stringify({id:`chatcmpl-${Date.now()}`,object:"chat.completion",model:e.model,choices:[{message:{role:"assistant",content:t.choices[0].message.content},finish_reason:t.choices[0].finish_reason}],usage:t.usage}))}async embed(e){let t=await this.hf.featureExtraction({model:e.model,inputs:Array.isArray(e.input)?e.input:[e.input]});return new Response(JSON.stringify({object:"list",data:Array.isArray(t[0])?t.map((s,o)=>({object:"embedding",embedding:s,index:o})):[{object:"embedding",embedding:t,index:0}],model:e.model}))}async image(e){let s=await(await this.hf.textToImage({model:e.model,inputs:e.prompt,parameters:{width:parseInt(e.size?.split("x")[0]||"1024"),height:parseInt(e.size?.split("x")[1]||"1024"),num_inference_steps:e.quality==="hd"?50:25}})).arrayBuffer(),o=Buffer.from(s).toString("base64");return new Response(JSON.stringify({data:[{b64_json:o}]}))}async audioTranscribe(e){let t=await fetch(e.input).then(o=>o.blob()),s=await this.hf.automaticSpeechRecognition({model:e.model,data:t});return new Response(JSON.stringify({text:s.text}))}async audioSummarize(e){let t=await fetch(e.input).then(m=>m.blob()),s=await this.hf.automaticSpeechRecognition({model:e.model||"openai/whisper-base",data:t}),o=await this.hf.summarization({model:"facebook/bart-large-cnn",inputs:s.text,parameters:{max_length:150,min_length:30}});return new Response(JSON.stringify({text:o.summary_text}))}async visionClassify(e){let t=await fetch(e.input).then(o=>o.blob()),s=await this.hf.imageClassification({model:e.model,data:t});return new Response(JSON.stringify({classifications:s.map(o=>({label:o.label,score:o.score}))}))}};var r=class extends Error{constructor(t,s,o){super(t);this.status=s;this.code=o;this.name="OpenModelsError"}};async function*p(a){if(!a.body)throw new r("Response body is null");if(a.status===401)throw new r("Invalid API key. Please check your credentials.",401);if(a.status===403)throw new r("Insufficient credits. Please top up your account.",403);let t=(await a.text()).split(`
`);for(let s of t){let o=s.trim();if(o!==""){if(o==="[DONE]")return;if(o.startsWith("data: ")){let m=o.slice(6);if(m==="[DONE]")return;try{let l=JSON.parse(m);l.choices?.[0]?.delta?.content&&(yield l.choices[0].delta.content)}catch{continue}}}}}var R={"image-classification":["google/vit-base-patch16-224","facebook/convnext-base-224","openai/clip-vit-base-patch32"],"text-generation":["microsoft/DialoGPT-medium","meta-llama/Llama-3.1-8B-Instruct","meta-llama/Meta-Llama-3-8B-Instruct"],embedding:["sentence-transformers/all-MiniLM-L6-v2"],"audio-transcribe":["openai/whisper-base"],"audio-summarize":["facebook/bart-large-cnn"],"image-generation":["runwayml/stable-diffusion-v1-5"]};function i(a){let e=R[a];if(!e||e.length===0)throw new Error(`No default models configured for task: ${a}`);return e[0]}var u=class{constructor(e={}){if(!e.apiKey)throw new r("API key is required. Please provide an API key in the client configuration.");if(!e.apiKey.startsWith("om_")||e.apiKey.length<10)throw new r('Invalid API key format. API keys must start with "om_" and be at least 10 characters long.');let t={apiKey:e.apiKey,hfToken:e.hfToken};this.textProvider=new n(t),this.embedProvider=new n(t),this.imageProvider=new n(t),this.audioProvider=new n(t),this.visionProvider=new n(t)}async chat(e){try{let t=await this.textProvider.chat(e);return e.stream?p(t):await t.json()}catch(t){throw t instanceof Error?new r(t.message):new r("Unknown error occurred")}}async embed(e){try{return await(await this.embedProvider.embed(e)).json()}catch(t){throw t instanceof Error?new r(t.message):new r("Unknown error occurred")}}async image(e){try{return await(await this.imageProvider.image(e)).json()}catch(t){throw t instanceof Error?new r(t.message):new r("Unknown error occurred")}}async run(e){try{switch(e.task){case"text-generation":{let t=e.model||i("text-generation"),s={...e,model:t},o=await this.textProvider.chat(s);return s.stream?p(o):await o.json()}case"image-generation":{let t=e.model||i("image-generation"),s={...e,model:t};return await(await this.imageProvider.image(s)).json()}case"embedding":{let t=e.model||i("embedding"),s={...e,model:t};return await(await this.embedProvider.embed(s)).json()}case"audio-transcribe":{let t=e.model||i("audio-transcribe"),s={...e,model:t};return await(await this.audioProvider.audioTranscribe(s)).json()}case"audio-summarize":{let t=e.model||i("audio-summarize"),s={...e,model:t};return await(await this.audioProvider.audioSummarize(s)).json()}case"image-classification":{let t=e.model||i("image-classification"),s={...e,model:t};return await(await this.visionProvider.visionClassify(s)).json()}default:throw new r("Unsupported task")}}catch(t){throw t instanceof Error?new r(t.message):new r("Unknown error occurred")}}};function f(a){return new u(a)}var S={"microsoft/DialoGPT-medium":{supportsTopP:!0,supportsStop:!0,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","float16"],maxTokenLimit:1e3,notes:"Conversational model, best for dialog"},"microsoft/DialoGPT-large":{supportsTopP:!0,supportsStop:!0,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","float16"],maxTokenLimit:1e3},"meta-llama/Llama-3.1-8B-Instruct":{supportsTopP:!0,supportsStop:!0,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","int4","float16"],maxTokenLimit:4096,notes:"Instruction-following model"},"meta-llama/Meta-Llama-3-8B-Instruct":{supportsTopP:!0,supportsStop:!0,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","int4","float16"],maxTokenLimit:4096,notes:"Instruction-following model with chat formatting"},"facebook/blenderbot-400M-distill":{supportsTopP:!0,supportsStop:!1,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","float16"],maxTokenLimit:128},"EleutherAI/gpt-neo-2.7B":{supportsTopP:!0,supportsStop:!0,supportsTemperature:!0,supportsMaxTokens:!0,supportsStreaming:!0,supportsQuantization:!0,supportedQuantizations:["int8","int4","float16"],maxTokenLimit:2048}},P={"runwayml/stable-diffusion-v1-5":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["float16"],notes:"Size, quality, style parameters supported"},"stabilityai/stable-diffusion-xl-base-1.0":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["float16"],notes:"Higher quality, slower generation"}},k={"sentence-transformers/all-MiniLM-L6-v2":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!1,notes:"Fast and efficient, good for most tasks"}},v={"google/vit-base-patch16-224":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"],notes:"Vision Transformer, good balance"},"facebook/convnext-base-224":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"]},"openai/clip-vit-base-patch32":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"]}},I={"openai/whisper-base":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"],notes:"Fast, good for most languages"},"openai/whisper-small":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"],notes:"Better accuracy than base"},"openai/whisper-medium":{supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!0,supportedQuantizations:["int8","float16"],notes:"High accuracy, slower"}};function g(a,e){let t={supportsTopP:!1,supportsStop:!1,supportsTemperature:!1,supportsMaxTokens:!1,supportsStreaming:!1,supportsQuantization:!1},s;switch(e){case"text":s=S;break;case"image":s=P;break;case"embed":s=k;break;case"vision":s=v;break;case"audio":s=I;break;default:return t}return s[a]||t}0&&(module.exports={OpenModels,OpenModelsError,client,getModelCapabilities,parseSSEStream});
//# sourceMappingURL=index.js.map