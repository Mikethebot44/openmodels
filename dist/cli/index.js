#!/usr/bin/env node
"use strict";var V=Object.create;var E=Object.defineProperty;var X=Object.getOwnPropertyDescriptor;var Y=Object.getOwnPropertyNames;var Z=Object.getPrototypeOf,ee=Object.prototype.hasOwnProperty;var oe=(t,e,o,s)=>{if(e&&typeof e=="object"||typeof e=="function")for(let a of Y(e))!ee.call(t,a)&&a!==o&&E(t,a,{get:()=>e[a],enumerable:!(s=X(e,a))||s.enumerable});return t};var p=(t,e,o)=>(o=t!=null?V(Z(t)):{},oe(e||!t||!t.__esModule?E(o,"default",{value:t,enumerable:!0}):o,t));var H=require("commander");var O=require("commander");var z=require("@huggingface/inference"),f=class{constructor(e){this.apiKey=e.apiKey;let o=e.hfToken||process.env.HF_TOKEN;if(!o)throw new Error("HuggingFace token is required");this.hf=new z.HfInference(o)}async chat(e){let o=await this.hf.chatCompletion({model:e.model,messages:e.messages,temperature:e.temperature,max_tokens:e.max_tokens,top_p:e.top_p,stop:e.stop,stream:e.stream||!1});return new Response(JSON.stringify({id:`chatcmpl-${Date.now()}`,object:"chat.completion",model:e.model,choices:[{message:{role:"assistant",content:o.choices[0].message.content},finish_reason:o.choices[0].finish_reason}],usage:o.usage}))}async embed(e){let o=await this.hf.featureExtraction({model:e.model,inputs:Array.isArray(e.input)?e.input:[e.input]});return new Response(JSON.stringify({object:"list",data:Array.isArray(o[0])?o.map((s,a)=>({object:"embedding",embedding:s,index:a})):[{object:"embedding",embedding:o,index:0}],model:e.model}))}async image(e){let s=await(await this.hf.textToImage({model:e.model,inputs:e.prompt,parameters:{width:parseInt(e.size?.split("x")[0]||"1024"),height:parseInt(e.size?.split("x")[1]||"1024"),num_inference_steps:e.quality==="hd"?50:25}})).arrayBuffer(),a=Buffer.from(s).toString("base64");return new Response(JSON.stringify({data:[{b64_json:a}]}))}async audioTranscribe(e){let o=await fetch(e.input).then(a=>a.blob()),s=await this.hf.automaticSpeechRecognition({model:e.model,data:o});return new Response(JSON.stringify({text:s.text}))}async audioSummarize(e){let o=await fetch(e.input).then(n=>n.blob()),s=await this.hf.automaticSpeechRecognition({model:e.model||"openai/whisper-base",data:o}),a=await this.hf.summarization({model:"facebook/bart-large-cnn",inputs:s.text,parameters:{max_length:150,min_length:30}});return new Response(JSON.stringify({text:a.summary_text}))}async visionClassify(e){let o=await fetch(e.input).then(a=>a.blob()),s=await this.hf.imageClassification({model:e.model,data:o});return new Response(JSON.stringify({classifications:s.map(a=>({label:a.label,score:a.score}))}))}};var i=class extends Error{constructor(o,s,a){super(o);this.status=s;this.code=a;this.name="OpenModelsError"}};async function*C(t){if(!t.body)throw new i("Response body is null");if(t.status===401)throw new i("Invalid API key. Please check your credentials.",401);if(t.status===403)throw new i("Insufficient credits. Please top up your account.",403);let o=(await t.text()).split(`
`);for(let s of o){let a=s.trim();if(a!==""){if(a==="[DONE]")return;if(a.startsWith("data: ")){let n=a.slice(6);if(n==="[DONE]")return;try{let r=JSON.parse(n);r.choices?.[0]?.delta?.content&&(yield r.choices[0].delta.content)}catch{continue}}}}}var te={"image-classification":["google/vit-base-patch16-224","facebook/convnext-base-224","openai/clip-vit-base-patch32"],"text-generation":["microsoft/DialoGPT-medium","meta-llama/Llama-3.1-8B-Instruct","meta-llama/Meta-Llama-3-8B-Instruct"],embedding:["sentence-transformers/all-MiniLM-L6-v2"],"audio-transcribe":["openai/whisper-base"],"audio-summarize":["facebook/bart-large-cnn"],"image-generation":["runwayml/stable-diffusion-v1-5"]};function b(t){let e=te[t];if(!e||e.length===0)throw new Error(`No default models configured for task: ${t}`);return e[0]}var v=class{constructor(e={}){if(!e.apiKey)throw new i("API key is required. Please provide an API key in the client configuration.");if(!e.apiKey.startsWith("om_")||e.apiKey.length<10)throw new i('Invalid API key format. API keys must start with "om_" and be at least 10 characters long.');let o={apiKey:e.apiKey,hfToken:e.hfToken};this.textProvider=new f(o),this.embedProvider=new f(o),this.imageProvider=new f(o),this.audioProvider=new f(o),this.visionProvider=new f(o)}async chat(e){try{let o=await this.textProvider.chat(e);return e.stream?C(o):await o.json()}catch(o){throw o instanceof Error?new i(o.message):new i("Unknown error occurred")}}async embed(e){try{return await(await this.embedProvider.embed(e)).json()}catch(o){throw o instanceof Error?new i(o.message):new i("Unknown error occurred")}}async image(e){try{return await(await this.imageProvider.image(e)).json()}catch(o){throw o instanceof Error?new i(o.message):new i("Unknown error occurred")}}async run(e){try{switch(e.task){case"text-generation":{let o=e.model||b("text-generation"),s={...e,model:o},a=await this.textProvider.chat(s);return s.stream?C(a):await a.json()}case"image-generation":{let o=e.model||b("image-generation"),s={...e,model:o};return await(await this.imageProvider.image(s)).json()}case"embedding":{let o=e.model||b("embedding"),s={...e,model:o};return await(await this.embedProvider.embed(s)).json()}case"audio-transcribe":{let o=e.model||b("audio-transcribe"),s={...e,model:o};return await(await this.audioProvider.audioTranscribe(s)).json()}case"audio-summarize":{let o=e.model||b("audio-summarize"),s={...e,model:o};return await(await this.audioProvider.audioSummarize(s)).json()}case"image-classification":{let o=e.model||b("image-classification"),s={...e,model:o};return await(await this.visionProvider.visionClassify(s)).json()}default:throw new i("Unsupported task")}}catch(o){throw o instanceof Error?new i(o.message):new i("Unknown error occurred")}}};function h(t){return new v(t)}var u=p(require("chalk")),I=p(require("ora"));var S=p(require("fs")),A=p(require("path")),L=p(require("os"));function g(){let t=A.join(L.homedir(),".openmodels","config.json");if(!S.existsSync(t))return{baseUrl:"https://modal.run/api/v1"};try{let e=JSON.parse(S.readFileSync(t,"utf8"));return e["base-url"]&&!e.baseUrl&&(e.baseUrl=e["base-url"]),e}catch{return console.log("Warning: Could not read config file, using defaults"),{baseUrl:"https://modal.run/api/v1"}}}var Q=new O.Command("chat").description("Chat with AI models").argument("[message]","Message to send to the AI").option("-m, --model <model>","Model to use","microsoft/DialoGPT-medium").option("-s, --stream","Stream the response",!1).option("-t, --temperature <temp>","Temperature for generation","0.7").option("-k, --max-tokens <tokens>","Maximum tokens to generate","200").option("-i, --interactive","Interactive chat mode",!1).action(async(t,e)=>{let o=g(),s=h(o);e.interactive?await ae(s,e):t?await se(s,t,e):(console.log(u.default.red("Error: Please provide a message or use --interactive mode")),process.exit(1))});async function se(t,e,o){let s=(0,I.default)("Generating response...").start();try{let a={model:o.model,messages:[{role:"user",content:e}],max_tokens:parseInt(o.maxTokens),temperature:parseFloat(o.temperature),stream:o.stream};if(o.stream){s.stop();let n=await t.chat(a);process.stdout.write(u.default.blue("Response: "));for await(let r of n)process.stdout.write(r);console.log()}else{let n=await t.chat(a);s.stop(),console.log(u.default.blue("Response:")),console.log(n.choices[0].message.content)}}catch(a){s.stop(),console.error(u.default.red("Error:"),a),process.exit(1)}}async function ae(t,e){console.log(u.default.green('Interactive chat mode. Type "exit" to quit.')),console.log(u.default.gray(`Using model: ${e.model}`));let s=require("readline").createInterface({input:process.stdin,output:process.stdout}),a=()=>{s.question(u.default.blue("You: "),async n=>{if(n.toLowerCase()==="exit"){s.close();return}let r=(0,I.default)("Generating response...").start();try{let d={model:e.model,messages:[{role:"user",content:n}],max_tokens:parseInt(e.maxTokens),temperature:parseFloat(e.temperature),stream:!1},R=await t.chat(d);r.stop(),console.log(u.default.green("AI:"),R.choices[0].message.content),console.log(),a()}catch(d){r.stop(),console.error(u.default.red("Error:"),d),a()}})};a()}var _=require("commander");var x=p(require("chalk")),j=p(require("ora"));var D=new _.Command("embed").description("Generate text embeddings").argument("<text>","Text to embed").option("-m, --model <model>","Embedding model to use","sentence-transformers/all-MiniLM-L6-v2").option("-f, --format <format>","Output format (json, values)","json").option("-u, --url <url>","Custom embedding backend URL").action(async(t,e)=>{let o=g(),s=e.url||o.embedUrl||o.baseUrl,a=h({baseUrl:s}),n=(0,j.default)("Generating embedding...").start();try{let r=await a.embed({model:e.model,input:t});n.stop(),e.format==="values"?(console.log(x.default.blue("Embedding values:")),console.log(r.data[0].embedding.slice(0,10).map(d=>d.toFixed(4)).join(", ")),console.log(x.default.gray(`... (${r.data[0].embedding.length} dimensions)`))):(console.log(x.default.blue("Embedding response:")),console.log(JSON.stringify(r,null,2)))}catch(r){n.stop(),console.error(x.default.red("Error:"),r),process.exit(1)}});var $=require("commander");var w=p(require("chalk")),B=p(require("ora")),U=p(require("fs")),G=p(require("path"));var q=new $.Command("image").description("Generate images from text prompts").argument("<prompt>","Text prompt for image generation").option("-m, --model <model>","Image model to use","stabilityai/stable-diffusion-xl-base-1.0").option("-s, --size <size>","Image size","1024x1024").option("-q, --quality <quality>","Image quality (standard, hd)","standard").option("-n, --number <number>","Number of images to generate","1").option("-o, --output <file>","Output file path").option("-u, --url <url>","Custom image backend URL").action(async(t,e)=>{let o=g(),s=e.url||o.imageUrl||o.baseUrl,a=h({baseUrl:s}),n=(0,B.default)("Generating image...").start();try{let r=await a.image({model:e.model,prompt:t,size:e.size,quality:e.quality,n:parseInt(e.number)});n.stop();let d=r.data[0];if(d.b64_json){let R=Buffer.from(d.b64_json,"base64"),W=e.output||`generated_image_${Date.now()}.png`,M=G.resolve(W);U.writeFileSync(M,R),console.log(w.default.green("\u2713 Image generated successfully!")),console.log(w.default.blue("Saved to:"),M),console.log(w.default.gray(`Model: ${r.model}`)),console.log(w.default.gray(`Size: ${e.size}`))}}catch(r){n.stop(),console.error(w.default.red("Error:"),r),process.exit(1)}});var F=require("commander"),m=p(require("chalk"));var N=new F.Command("models").description("List available models").option("-t, --type <type>","Filter by model type (text, embed, image)","all").action(async t=>{let e=g(),o={text:["microsoft/DialoGPT-medium","microsoft/DialoGPT-large","facebook/blenderbot-400M-distill","EleutherAI/gpt-neo-2.7B","EleutherAI/gpt-j-6B","microsoft/DialoGPT-small","distilgpt2"],embed:["sentence-transformers/all-MiniLM-L6-v2","sentence-transformers/all-mpnet-base-v2","BAAI/bge-large-en","BAAI/bge-base-en","sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2","sentence-transformers/all-MiniLM-L12-v2"],image:["stabilityai/stable-diffusion-xl-base-1.0","runwayml/stable-diffusion-v1-5","stabilityai/stable-diffusion-2-1","CompVis/stable-diffusion-v1-4"]};t.type==="all"?(console.log(m.default.blue("Available Models:")),console.log(),console.log(m.default.green("Text Generation Models:")),o.text.forEach(s=>{console.log(`  ${m.default.cyan("\u2022")} ${s}`)}),console.log(),console.log(m.default.green("Embedding Models:")),o.embed.forEach(s=>{console.log(`  ${m.default.cyan("\u2022")} ${s}`)}),console.log(),console.log(m.default.green("Image Generation Models:")),o.image.forEach(s=>{console.log(`  ${m.default.cyan("\u2022")} ${s}`)})):o[t.type]?(console.log(m.default.blue(`${t.type.charAt(0).toUpperCase()+t.type.slice(1)} Models:`)),o[t.type].forEach(s=>{console.log(`  ${m.default.cyan("\u2022")} ${s}`)})):(console.log(m.default.red("Error: Invalid model type. Use: text, embed, image, or all")),process.exit(1))});var J=require("commander"),c=p(require("chalk")),l=p(require("fs")),T=p(require("path")),P=p(require("os")),k=new J.Command("config").description("Manage OpenModels configuration").command("set").description("Set configuration values").argument("<key>","Configuration key (api-key, base-url, embed-url, image-url)").argument("<value>","Configuration value").action(async(t,e)=>{let o=T.join(P.homedir(),".openmodels","config.json"),s=T.dirname(o);l.existsSync(s)||l.mkdirSync(s,{recursive:!0});let a={};if(l.existsSync(o))try{a=JSON.parse(l.readFileSync(o,"utf8"))}catch{console.log(c.default.yellow("Warning: Could not read existing config, creating new one"))}a[t]=e,l.writeFileSync(o,JSON.stringify(a,null,2)),console.log(c.default.green(`\u2713 Set ${t} = ${e}`))});k.command("get").description("Get configuration values").argument("[key]","Configuration key to get (optional)").action(async t=>{let e=K();t?e[t]?console.log(c.default.blue(`${t}:`),e[t]):(console.log(c.default.red(`Configuration key '${t}' not found`)),process.exit(1)):(console.log(c.default.blue("Current configuration:")),Object.entries(e).forEach(([o,s])=>{console.log(`  ${c.default.cyan(o)}: ${s}`)}))});k.command("list").description("List all configuration values").action(async()=>{let t=K();console.log(c.default.blue("Current configuration:")),Object.entries(t).forEach(([e,o])=>{console.log(`  ${c.default.cyan(e)}: ${o}`)})});function K(){let t=T.join(P.homedir(),".openmodels","config.json");if(!l.existsSync(t))return{baseUrl:"https://modal.run/api/v1"};try{return JSON.parse(l.readFileSync(t,"utf8"))}catch{return console.log(c.default.yellow("Warning: Could not read config file, using defaults")),{baseUrl:"https://modal.run/api/v1"}}}var y=new H.Command;y.name("openmodels").description("CLI for OpenModels - Open-source AI models SDK").version("0.3.0");y.addCommand(Q);y.addCommand(D);y.addCommand(q);y.addCommand(N);y.addCommand(k);y.parse();
//# sourceMappingURL=index.js.map