#!/usr/bin/env node
"use strict";var Y=Object.create;var q=Object.defineProperty;var Z=Object.getOwnPropertyDescriptor;var ee=Object.getOwnPropertyNames;var te=Object.getPrototypeOf,oe=Object.prototype.hasOwnProperty;var se=(s,e,o,r)=>{if(e&&typeof e=="object"||typeof e=="function")for(let t of ee(e))!oe.call(s,t)&&t!==o&&q(s,t,{get:()=>e[t],enumerable:!(r=Z(e,t))||r.enumerable});return s};var p=(s,e,o)=>(o=s!=null?Y(te(s)):{},se(e||!s||!s.__esModule?q(o,"default",{value:s,enumerable:!0}):o,s));var H=require("commander");var L=require("commander");var y=p(require("node-fetch"));var C=class{constructor(e){this.config=e}};var a=class extends Error{constructor(o,r,t){super(o);this.status=r;this.code=t;this.name="OpenModelsError"}};async function*S(s){if(!s.body)throw new a("Response body is null");if(s.status===401)throw new a("Invalid API key. Please check your credentials.",401);if(s.status===403)throw new a("Insufficient credits. Please top up your account.",403);let o=(await s.text()).split(`
`);for(let r of o){let t=r.trim();if(t!==""){if(t==="[DONE]")return;if(t.startsWith("data: ")){let n=t.slice(6);if(n==="[DONE]")return;try{let i=JSON.parse(n);i.choices?.[0]?.delta?.content&&(yield i.choices[0].delta.content)}catch{continue}}}}}var d=class extends C{async chat(e){let o=`${this.config.baseUrl}/chat`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}async embed(e){let o=`${this.config.baseUrl}/embed`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}async image(e){let o=`${this.config.baseUrl}/image`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}async audioTranscribe(e){let o=`${this.config.baseUrl}/transcribe`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}async audioSummarize(e){let o=`${this.config.baseUrl}/summarize`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}async visionClassify(e){let o=`${this.config.baseUrl}/classify`,r={"Content-Type":"application/json",Authorization:`Bearer ${this.config.apiKey}`},t=await(0,y.default)(o,{method:"POST",headers:r,body:JSON.stringify(e)});if(!t.ok){let n=await t.text();throw t.status===401?new a("Invalid API key. Please check your credentials.",401):t.status===403?new a("Insufficient credits. Please top up your account.",403):new a(`Modal API error: ${t.status} ${n}`,t.status)}return t}};var re={"image-classification":["google/vit-base-patch16-224","facebook/convnext-base-224","openai/clip-vit-base-patch32"],"text-generation":["microsoft/DialoGPT-medium","meta-llama/Llama-3.1-8B-Instruct","meta-llama/Meta-Llama-3-8B-Instruct"],embedding:["sentence-transformers/all-MiniLM-L6-v2"],"audio-transcribe":["openai/whisper-base"],"audio-summarize":["facebook/bart-large-cnn"],"image-generation":["runwayml/stable-diffusion-v1-5"]};function h(s){let e=re[s];if(!e||e.length===0)throw new Error(`No default models configured for task: ${s}`);return e[0]}var ae={text:"https://mikethebot44--tryscout-text-create-app.modal.run",embed:"https://mikethebot44--tryscout-embed-create-app.modal.run",image:"https://mikethebot44--tryscout-image-create-app.modal.run",audio:"https://mikethebot44--tryscout-audio-create-app.modal.run",vision:"https://mikethebot44--tryscout-vision-create-app.modal.run"};function x(s){return ae[s]}var k=class{constructor(e={}){if(!e.apiKey)throw new a("API key is required. Please provide an API key in the client configuration.");if(!e.apiKey.startsWith("om_")||e.apiKey.length<10)throw new a('Invalid API key format. API keys must start with "om_" and be at least 10 characters long.');this.textProvider=new d({apiKey:e.apiKey,baseUrl:x("text")}),this.embedProvider=new d({apiKey:e.apiKey,baseUrl:x("embed")}),this.imageProvider=new d({apiKey:e.apiKey,baseUrl:x("image")}),this.audioProvider=new d({apiKey:e.apiKey,baseUrl:x("audio")}),this.visionProvider=new d({apiKey:e.apiKey,baseUrl:x("vision")})}async chat(e){try{let o=await this.textProvider.chat(e);return e.stream?S(o):await o.json()}catch(o){throw o instanceof Error?new a(o.message):new a("Unknown error occurred")}}async embed(e){try{return await(await this.embedProvider.embed(e)).json()}catch(o){throw o instanceof Error?new a(o.message):new a("Unknown error occurred")}}async image(e){try{return await(await this.imageProvider.image(e)).json()}catch(o){throw o instanceof Error?new a(o.message):new a("Unknown error occurred")}}async run(e){try{switch(e.task){case"text-generation":{let o=e.model||h("text-generation"),r={...e,model:o},t=await this.textProvider.chat(r);return r.stream?S(t):await t.json()}case"image-generation":{let o=e.model||h("image-generation"),r={...e,model:o};return await(await this.imageProvider.image(r)).json()}case"embedding":{let o=e.model||h("embedding"),r={...e,model:o};return await(await this.embedProvider.embed(r)).json()}case"audio-transcribe":{let o=e.model||h("audio-transcribe"),r={...e,model:o};return await(await this.audioProvider.audioTranscribe(r)).json()}case"audio-summarize":{let o=e.model||h("audio-summarize"),r={...e,model:o};return await(await this.audioProvider.audioSummarize(r)).json()}case"image-classification":{let o=e.model||h("image-classification"),r={...e,model:o};return await(await this.visionProvider.visionClassify(r)).json()}default:throw new a("Unsupported task")}}catch(o){throw o instanceof Error?new a(o.message):new a("Unknown error occurred")}}};function b(s){return new k(s)}var m=p(require("chalk")),A=p(require("ora"));var I=p(require("fs")),$=p(require("path")),O=p(require("os"));function g(){let s=$.join(O.homedir(),".openmodels","config.json");if(!I.existsSync(s))return{baseUrl:"https://modal.run/api/v1"};try{let e=JSON.parse(I.readFileSync(s,"utf8"));return e["base-url"]&&!e.baseUrl&&(e.baseUrl=e["base-url"]),e}catch{return console.log("Warning: Could not read config file, using defaults"),{baseUrl:"https://modal.run/api/v1"}}}var U=new L.Command("chat").description("Chat with AI models").argument("[message]","Message to send to the AI").option("-m, --model <model>","Model to use","microsoft/DialoGPT-medium").option("-s, --stream","Stream the response",!1).option("-t, --temperature <temp>","Temperature for generation","0.7").option("-k, --max-tokens <tokens>","Maximum tokens to generate","200").option("-i, --interactive","Interactive chat mode",!1).action(async(s,e)=>{let o=g(),r=b(o);e.interactive?await ie(r,e):s?await ne(r,s,e):(console.log(m.default.red("Error: Please provide a message or use --interactive mode")),process.exit(1))});async function ne(s,e,o){let r=(0,A.default)("Generating response...").start();try{let t={model:o.model,messages:[{role:"user",content:e}],max_tokens:parseInt(o.maxTokens),temperature:parseFloat(o.temperature),stream:o.stream};if(o.stream){r.stop();let n=await s.chat(t);process.stdout.write(m.default.blue("Response: "));for await(let i of n)process.stdout.write(i);console.log()}else{let n=await s.chat(t);r.stop(),console.log(m.default.blue("Response:")),console.log(n.choices[0].message.content)}}catch(t){r.stop(),console.error(m.default.red("Error:"),t),process.exit(1)}}async function ie(s,e){console.log(m.default.green('Interactive chat mode. Type "exit" to quit.')),console.log(m.default.gray(`Using model: ${e.model}`));let r=require("readline").createInterface({input:process.stdin,output:process.stdout}),t=()=>{r.question(m.default.blue("You: "),async n=>{if(n.toLowerCase()==="exit"){r.close();return}let i=(0,A.default)("Generating response...").start();try{let f={model:e.model,messages:[{role:"user",content:n}],max_tokens:parseInt(e.maxTokens),temperature:parseFloat(e.temperature),stream:!1},R=await s.chat(f);i.stop(),console.log(m.default.green("AI:"),R.choices[0].message.content),console.log(),t()}catch(f){i.stop(),console.error(m.default.red("Error:"),f),t()}})};t()}var Q=require("commander");var T=p(require("chalk")),j=p(require("ora"));var B=new Q.Command("embed").description("Generate text embeddings").argument("<text>","Text to embed").option("-m, --model <model>","Embedding model to use","sentence-transformers/all-MiniLM-L6-v2").option("-f, --format <format>","Output format (json, values)","json").option("-u, --url <url>","Custom embedding backend URL").action(async(s,e)=>{let o=g(),r=e.url||o.embedUrl||o.baseUrl,t=b({baseUrl:r}),n=(0,j.default)("Generating embedding...").start();try{let i=await t.embed({model:e.model,input:s});n.stop(),e.format==="values"?(console.log(T.default.blue("Embedding values:")),console.log(i.data[0].embedding.slice(0,10).map(f=>f.toFixed(4)).join(", ")),console.log(T.default.gray(`... (${i.data[0].embedding.length} dimensions)`))):(console.log(T.default.blue("Embedding response:")),console.log(JSON.stringify(i,null,2)))}catch(i){n.stop(),console.error(T.default.red("Error:"),i),process.exit(1)}});var D=require("commander");var P=p(require("chalk")),_=p(require("ora")),G=p(require("fs")),K=p(require("path"));var N=new D.Command("image").description("Generate images from text prompts").argument("<prompt>","Text prompt for image generation").option("-m, --model <model>","Image model to use","stabilityai/stable-diffusion-xl-base-1.0").option("-s, --size <size>","Image size","1024x1024").option("-q, --quality <quality>","Image quality (standard, hd)","standard").option("-n, --number <number>","Number of images to generate","1").option("-o, --output <file>","Output file path").option("-u, --url <url>","Custom image backend URL").action(async(s,e)=>{let o=g(),r=e.url||o.imageUrl||o.baseUrl,t=b({baseUrl:r}),n=(0,_.default)("Generating image...").start();try{let i=await t.image({model:e.model,prompt:s,size:e.size,quality:e.quality,n:parseInt(e.number)});n.stop();let f=i.data[0];if(f.b64_json){let R=Buffer.from(f.b64_json,"base64"),X=e.output||`generated_image_${Date.now()}.png`,E=K.resolve(X);G.writeFileSync(E,R),console.log(P.default.green("\u2713 Image generated successfully!")),console.log(P.default.blue("Saved to:"),E),console.log(P.default.gray(`Model: ${i.model}`)),console.log(P.default.gray(`Size: ${e.size}`))}}catch(i){n.stop(),console.error(P.default.red("Error:"),i),process.exit(1)}});var J=require("commander"),u=p(require("chalk"));var F=new J.Command("models").description("List available models").option("-t, --type <type>","Filter by model type (text, embed, image)","all").action(async s=>{let e=g(),o={text:["microsoft/DialoGPT-medium","microsoft/DialoGPT-large","facebook/blenderbot-400M-distill","EleutherAI/gpt-neo-2.7B","EleutherAI/gpt-j-6B","microsoft/DialoGPT-small","distilgpt2"],embed:["sentence-transformers/all-MiniLM-L6-v2","sentence-transformers/all-mpnet-base-v2","BAAI/bge-large-en","BAAI/bge-base-en","sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2","sentence-transformers/all-MiniLM-L12-v2"],image:["stabilityai/stable-diffusion-xl-base-1.0","runwayml/stable-diffusion-v1-5","stabilityai/stable-diffusion-2-1","CompVis/stable-diffusion-v1-4"]};s.type==="all"?(console.log(u.default.blue("Available Models:")),console.log(),console.log(u.default.green("Text Generation Models:")),o.text.forEach(r=>{console.log(`  ${u.default.cyan("\u2022")} ${r}`)}),console.log(),console.log(u.default.green("Embedding Models:")),o.embed.forEach(r=>{console.log(`  ${u.default.cyan("\u2022")} ${r}`)}),console.log(),console.log(u.default.green("Image Generation Models:")),o.image.forEach(r=>{console.log(`  ${u.default.cyan("\u2022")} ${r}`)})):o[s.type]?(console.log(u.default.blue(`${s.type.charAt(0).toUpperCase()+s.type.slice(1)} Models:`)),o[s.type].forEach(r=>{console.log(`  ${u.default.cyan("\u2022")} ${r}`)})):(console.log(u.default.red("Error: Invalid model type. Use: text, embed, image, or all")),process.exit(1))});var W=require("commander"),c=p(require("chalk")),l=p(require("fs")),v=p(require("path")),z=p(require("os")),M=new W.Command("config").description("Manage OpenModels configuration").command("set").description("Set configuration values").argument("<key>","Configuration key (api-key, base-url, embed-url, image-url)").argument("<value>","Configuration value").action(async(s,e)=>{let o=v.join(z.homedir(),".openmodels","config.json"),r=v.dirname(o);l.existsSync(r)||l.mkdirSync(r,{recursive:!0});let t={};if(l.existsSync(o))try{t=JSON.parse(l.readFileSync(o,"utf8"))}catch{console.log(c.default.yellow("Warning: Could not read existing config, creating new one"))}t[s]=e,l.writeFileSync(o,JSON.stringify(t,null,2)),console.log(c.default.green(`\u2713 Set ${s} = ${e}`))});M.command("get").description("Get configuration values").argument("[key]","Configuration key to get (optional)").action(async s=>{let e=V();s?e[s]?console.log(c.default.blue(`${s}:`),e[s]):(console.log(c.default.red(`Configuration key '${s}' not found`)),process.exit(1)):(console.log(c.default.blue("Current configuration:")),Object.entries(e).forEach(([o,r])=>{console.log(`  ${c.default.cyan(o)}: ${r}`)}))});M.command("list").description("List all configuration values").action(async()=>{let s=V();console.log(c.default.blue("Current configuration:")),Object.entries(s).forEach(([e,o])=>{console.log(`  ${c.default.cyan(e)}: ${o}`)})});function V(){let s=v.join(z.homedir(),".openmodels","config.json");if(!l.existsSync(s))return{baseUrl:"https://modal.run/api/v1"};try{return JSON.parse(l.readFileSync(s,"utf8"))}catch{return console.log(c.default.yellow("Warning: Could not read config file, using defaults")),{baseUrl:"https://modal.run/api/v1"}}}var w=new H.Command;w.name("openmodels").description("CLI for OpenModels - Open-source AI models SDK").version("0.3.0");w.addCommand(U);w.addCommand(B);w.addCommand(N);w.addCommand(F);w.addCommand(M);w.parse();
//# sourceMappingURL=index.js.map