{"version":3,"sources":["../../cli/index.ts","../../cli/commands/chat.ts","../../cli/utils.ts","../../cli/commands/embed.ts","../../cli/commands/image.ts","../../cli/commands/models.ts","../../cli/commands/config.ts"],"sourcesContent":["#!/usr/bin/env node\r\n\r\nimport { Command } from 'commander';\r\nimport { chatCommand } from './commands/chat';\r\nimport { embedCommand } from './commands/embed';\r\nimport { imageCommand } from './commands/image';\r\nimport { modelsCommand } from './commands/models';\r\nimport { configCommand } from './commands/config';\r\n\r\nconst program = new Command();\r\n\r\nprogram\r\n  .name('openmodels')\r\n  .description('CLI for OpenModels - Open-source AI models SDK')\r\n  .version('0.3.0');\r\n\r\n// Add commands\r\nprogram.addCommand(chatCommand);\r\nprogram.addCommand(embedCommand);\r\nprogram.addCommand(imageCommand);\r\nprogram.addCommand(modelsCommand);\r\nprogram.addCommand(configCommand);\r\n\r\nprogram.parse();\r\n","import { Command } from 'commander';\nimport { client } from '../../src';\nimport chalk from 'chalk';\nimport ora from 'ora';\nimport { readConfig } from '../utils';\n\nexport const chatCommand = new Command('chat')\n  .description('Chat with AI models')\n  .argument('[message]', 'Message to send to the AI')\n  .option('-m, --model <model>', 'Model to use', 'microsoft/DialoGPT-medium')\n  .option('-s, --stream', 'Stream the response', false)\n  .option('-t, --temperature <temp>', 'Temperature for generation', '0.7')\n  .option('-k, --max-tokens <tokens>', 'Maximum tokens to generate', '200')\n  .option('-i, --interactive', 'Interactive chat mode', false)\n  .action(async (message, options) => {\n    const config = readConfig();\n    const openmodels = client(config);\n\n    if (options.interactive) {\n      await interactiveChat(openmodels, options);\n    } else if (message) {\n      await singleChat(openmodels, message, options);\n    } else {\n      console.log(chalk.red('Error: Please provide a message or use --interactive mode'));\n      process.exit(1);\n    }\n  });\n\nasync function singleChat(openmodels: any, message: string, options: any) {\n  const spinner = ora('Generating response...').start();\n  \n  try {\n    const request = {\n      model: options.model,\n      messages: [\n        { role: 'user', content: message }\n      ],\n      max_tokens: parseInt(options.maxTokens),\n      temperature: parseFloat(options.temperature),\n      stream: options.stream\n    };\n\n    if (options.stream) {\n      spinner.stop();\n      const stream = await openmodels.chat(request) as AsyncGenerator<string, void, unknown>;\n      \n      process.stdout.write(chalk.blue('Response: '));\n      for await (const token of stream) {\n        process.stdout.write(token);\n      }\n      console.log();\n    } else {\n      const response = await openmodels.chat(request);\n      spinner.stop();\n      \n      console.log(chalk.blue('Response:'));\n      console.log(response.choices[0].message.content);\n    }\n  } catch (error) {\n    spinner.stop();\n    console.error(chalk.red('Error:'), error);\n    process.exit(1);\n  }\n}\n\nasync function interactiveChat(openmodels: any, options: any) {\n  console.log(chalk.green('Interactive chat mode. Type \"exit\" to quit.'));\n  console.log(chalk.gray(`Using model: ${options.model}`));\n  \n  const readline = require('readline');\n  const rl = readline.createInterface({\n    input: process.stdin,\n    output: process.stdout\n  });\n\n  const askQuestion = () => {\n    rl.question(chalk.blue('You: '), async (input: string) => {\n      if (input.toLowerCase() === 'exit') {\n        rl.close();\n        return;\n      }\n\n      const spinner = ora('Generating response...').start();\n      \n      try {\n        const request = {\n          model: options.model,\n          messages: [\n            { role: 'user', content: input }\n          ],\n          max_tokens: parseInt(options.maxTokens),\n          temperature: parseFloat(options.temperature),\n          stream: false\n        };\n\n        const response = await openmodels.chat(request);\n        spinner.stop();\n        \n        console.log(chalk.green('AI:'), response.choices[0].message.content);\n        console.log();\n        askQuestion();\n      } catch (error) {\n        spinner.stop();\n        console.error(chalk.red('Error:'), error);\n        askQuestion();\n      }\n    });\n  };\n\n  askQuestion();\n}\n","import * as fs from 'fs';\nimport * as path from 'path';\nimport * as os from 'os';\n\nexport function readConfig(): any {\n  const configPath = path.join(os.homedir(), '.openmodels', 'config.json');\n  \n  if (!fs.existsSync(configPath)) {\n    return {\n      baseUrl: 'https://modal.run/api/v1'\n    };\n  }\n  \n  try {\n    const config = JSON.parse(fs.readFileSync(configPath, 'utf8'));\n    \n    // Handle both 'base-url' and 'baseUrl' formats\n    if (config['base-url'] && !config.baseUrl) {\n      config.baseUrl = config['base-url'];\n    }\n    \n    return config;\n  } catch (error) {\n    console.log('Warning: Could not read config file, using defaults');\n    return {\n      baseUrl: 'https://modal.run/api/v1'\n    };\n  }\n}\n","import { Command } from 'commander';\r\nimport { client } from '../../src';\r\nimport chalk from 'chalk';\r\nimport ora from 'ora';\r\nimport { readConfig } from '../utils';\r\n\r\nexport const embedCommand = new Command('embed')\r\n  .description('Generate text embeddings')\r\n  .argument('<text>', 'Text to embed')\r\n  .option('-m, --model <model>', 'Embedding model to use', 'sentence-transformers/all-MiniLM-L6-v2')\r\n  .option('-f, --format <format>', 'Output format (json, values)', 'json')\r\n  .option('-u, --url <url>', 'Custom embedding backend URL')\r\n  .action(async (text, options) => {\r\n    const config = readConfig();\r\n    \r\n    // Use custom URL if provided, otherwise try to get embedding URL from config\r\n    const baseUrl = options.url || config.embedUrl || config.baseUrl;\r\n    \r\n    const openmodels = client({ baseUrl });\r\n\r\n    const spinner = ora('Generating embedding...').start();\r\n    \r\n    try {\r\n      const response = await openmodels.embed({\r\n        model: options.model,\r\n        input: text,\r\n      });\r\n\r\n      spinner.stop();\r\n\r\n      if (options.format === 'values') {\r\n        console.log(chalk.blue('Embedding values:'));\r\n        console.log(response.data[0].embedding.slice(0, 10).map((v: number) => v.toFixed(4)).join(', '));\r\n        console.log(chalk.gray(`... (${response.data[0].embedding.length} dimensions)`));\r\n      } else {\r\n        console.log(chalk.blue('Embedding response:'));\r\n        console.log(JSON.stringify(response, null, 2));\r\n      }\r\n    } catch (error) {\r\n      spinner.stop();\r\n      console.error(chalk.red('Error:'), error);\r\n      process.exit(1);\r\n    }\r\n  });\r\n","import { Command } from 'commander';\r\nimport { client } from '../../src';\r\nimport chalk from 'chalk';\r\nimport ora from 'ora';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport { readConfig } from '../utils';\r\n\r\nexport const imageCommand = new Command('image')\r\n  .description('Generate images from text prompts')\r\n  .argument('<prompt>', 'Text prompt for image generation')\r\n  .option('-m, --model <model>', 'Image model to use', 'stabilityai/stable-diffusion-xl-base-1.0')\r\n  .option('-s, --size <size>', 'Image size', '1024x1024')\r\n  .option('-q, --quality <quality>', 'Image quality (standard, hd)', 'standard')\r\n  .option('-n, --number <number>', 'Number of images to generate', '1')\r\n  .option('-o, --output <file>', 'Output file path')\r\n  .option('-u, --url <url>', 'Custom image backend URL')\r\n  .action(async (prompt, options) => {\r\n    const config = readConfig();\r\n    \r\n    // Use custom URL if provided, otherwise try to get image URL from config\r\n    const baseUrl = options.url || config.imageUrl || config.baseUrl;\r\n    \r\n    const openmodels = client({ baseUrl });\r\n\r\n    const spinner = ora('Generating image...').start();\r\n    \r\n    try {\r\n      const response = await openmodels.image({\r\n        model: options.model,\r\n        prompt: prompt,\r\n        size: options.size,\r\n        quality: options.quality,\r\n        n: parseInt(options.number)\r\n      });\r\n\r\n      spinner.stop();\r\n\r\n      const imageData = response.data[0];\r\n      if (imageData.b64_json) {\r\n        const imageBuffer = Buffer.from(imageData.b64_json, 'base64');\r\n        \r\n        const filename = options.output || `generated_image_${Date.now()}.png`;\r\n        const filepath = path.resolve(filename);\r\n        \r\n        fs.writeFileSync(filepath, imageBuffer);\r\n        \r\n        console.log(chalk.green('✓ Image generated successfully!'));\r\n        console.log(chalk.blue('Saved to:'), filepath);\r\n        console.log(chalk.gray(`Model: ${response.model}`));\r\n        console.log(chalk.gray(`Size: ${options.size}`));\r\n      }\r\n    } catch (error) {\r\n      spinner.stop();\r\n      console.error(chalk.red('Error:'), error);\r\n      process.exit(1);\r\n    }\r\n  });\r\n","import { Command } from 'commander';\r\nimport chalk from 'chalk';\r\nimport { readConfig } from '../utils';\r\n\r\nexport const modelsCommand = new Command('models')\r\n  .description('List available models')\r\n  .option('-t, --type <type>', 'Filter by model type (text, embed, image)', 'all')\r\n  .action(async (options) => {\r\n    const config = readConfig();\r\n    \r\n    const models = {\r\n      text: [\r\n        'microsoft/DialoGPT-medium',\r\n        'microsoft/DialoGPT-large',\r\n        'facebook/blenderbot-400M-distill',\r\n        'EleutherAI/gpt-neo-2.7B',\r\n        'EleutherAI/gpt-j-6B',\r\n        'microsoft/DialoGPT-small',\r\n        'distilgpt2'\r\n      ],\r\n      embed: [\r\n        'sentence-transformers/all-MiniLM-L6-v2',\r\n        'sentence-transformers/all-mpnet-base-v2',\r\n        'BAAI/bge-large-en',\r\n        'BAAI/bge-base-en',\r\n        'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\r\n        'sentence-transformers/all-MiniLM-L12-v2'\r\n      ],\r\n      image: [\r\n        'stabilityai/stable-diffusion-xl-base-1.0',\r\n        'runwayml/stable-diffusion-v1-5',\r\n        'stabilityai/stable-diffusion-2-1',\r\n        'CompVis/stable-diffusion-v1-4'\r\n      ]\r\n    };\r\n\r\n    if (options.type === 'all') {\r\n      console.log(chalk.blue('Available Models:'));\r\n      console.log();\r\n      \r\n      console.log(chalk.green('Text Generation Models:'));\r\n      models.text.forEach(model => {\r\n        console.log(`  ${chalk.cyan('•')} ${model}`);\r\n      });\r\n      \r\n      console.log();\r\n      console.log(chalk.green('Embedding Models:'));\r\n      models.embed.forEach(model => {\r\n        console.log(`  ${chalk.cyan('•')} ${model}`);\r\n      });\r\n      \r\n      console.log();\r\n      console.log(chalk.green('Image Generation Models:'));\r\n      models.image.forEach(model => {\r\n        console.log(`  ${chalk.cyan('•')} ${model}`);\r\n      });\r\n    } else if (models[options.type as keyof typeof models]) {\r\n      console.log(chalk.blue(`${options.type.charAt(0).toUpperCase() + options.type.slice(1)} Models:`));\r\n      models[options.type as keyof typeof models].forEach(model => {\r\n        console.log(`  ${chalk.cyan('•')} ${model}`);\r\n      });\r\n    } else {\r\n      console.log(chalk.red('Error: Invalid model type. Use: text, embed, image, or all'));\r\n      process.exit(1);\r\n    }\r\n  });\r\n","import { Command } from 'commander';\r\nimport chalk from 'chalk';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\nimport * as os from 'os';\r\n\r\nexport const configCommand = new Command('config')\r\n  .description('Manage OpenModels configuration')\r\n  .command('set')\r\n  .description('Set configuration values')\r\n  .argument('<key>', 'Configuration key (api-key, base-url, embed-url, image-url)')\r\n  .argument('<value>', 'Configuration value')\r\n  .action(async (key, value) => {\r\n    const configPath = path.join(os.homedir(), '.openmodels', 'config.json');\r\n    const configDir = path.dirname(configPath);\r\n    \r\n    // Ensure config directory exists\r\n    if (!fs.existsSync(configDir)) {\r\n      fs.mkdirSync(configDir, { recursive: true });\r\n    }\r\n    \r\n    // Read existing config\r\n    let config: any = {};\r\n    if (fs.existsSync(configPath)) {\r\n      try {\r\n        config = JSON.parse(fs.readFileSync(configPath, 'utf8'));\r\n      } catch (error) {\r\n        console.log(chalk.yellow('Warning: Could not read existing config, creating new one'));\r\n      }\r\n    }\r\n    \r\n    // Update config\r\n    config[key] = value;\r\n    \r\n    // Write config\r\n    fs.writeFileSync(configPath, JSON.stringify(config, null, 2));\r\n    \r\n    console.log(chalk.green(`✓ Set ${key} = ${value}`));\r\n  });\r\n\r\nconfigCommand\r\n  .command('get')\r\n  .description('Get configuration values')\r\n  .argument('[key]', 'Configuration key to get (optional)')\r\n  .action(async (key) => {\r\n    const config = readConfig();\r\n    \r\n    if (key) {\r\n      if (config[key]) {\r\n        console.log(chalk.blue(`${key}:`), config[key]);\r\n      } else {\r\n        console.log(chalk.red(`Configuration key '${key}' not found`));\r\n        process.exit(1);\r\n      }\r\n    } else {\r\n      console.log(chalk.blue('Current configuration:'));\r\n      Object.entries(config).forEach(([k, v]) => {\r\n        console.log(`  ${chalk.cyan(k)}: ${v}`);\r\n      });\r\n    }\r\n  });\r\n\r\nconfigCommand\r\n  .command('list')\r\n  .description('List all configuration values')\r\n  .action(async () => {\r\n    const config = readConfig();\r\n    \r\n    console.log(chalk.blue('Current configuration:'));\r\n    Object.entries(config).forEach(([k, v]) => {\r\n      console.log(`  ${chalk.cyan(k)}: ${v}`);\r\n    });\r\n  });\r\n\r\nexport function readConfig(): any {\r\n  const configPath = path.join(os.homedir(), '.openmodels', 'config.json');\r\n  \r\n  if (!fs.existsSync(configPath)) {\r\n    return {\r\n      baseUrl: 'https://modal.run/api/v1'\r\n    };\r\n  }\r\n  \r\n  try {\r\n    return JSON.parse(fs.readFileSync(configPath, 'utf8'));\r\n  } catch (error) {\r\n    console.log(chalk.yellow('Warning: Could not read config file, using defaults'));\r\n    return {\r\n      baseUrl: 'https://modal.run/api/v1'\r\n    };\r\n  }\r\n}\r\n"],"mappings":";iDAEA,OAAS,WAAAA,MAAe,YCFxB,OAAS,WAAAC,MAAe,YAExB,OAAOC,MAAW,QAClB,OAAOC,MAAS,MCHhB,UAAYC,MAAQ,KACpB,UAAYC,MAAU,OACtB,UAAYC,MAAQ,KAEb,SAASC,GAAkB,CAChC,IAAMC,EAAkB,OAAQ,UAAQ,EAAG,cAAe,aAAa,EAEvE,GAAI,CAAI,aAAWA,CAAU,EAC3B,MAAO,CACL,QAAS,0BACX,EAGF,GAAI,CACF,IAAMC,EAAS,KAAK,MAAS,eAAaD,EAAY,MAAM,CAAC,EAG7D,OAAIC,EAAO,UAAU,GAAK,CAACA,EAAO,UAChCA,EAAO,QAAUA,EAAO,UAAU,GAG7BA,CACT,MAAgB,CACd,eAAQ,IAAI,qDAAqD,EAC1D,CACL,QAAS,0BACX,CACF,CACF,CDtBO,IAAMC,EAAc,IAAIC,EAAQ,MAAM,EAC1C,YAAY,qBAAqB,EACjC,SAAS,YAAa,2BAA2B,EACjD,OAAO,sBAAuB,eAAgB,2BAA2B,EACzE,OAAO,eAAgB,sBAAuB,EAAK,EACnD,OAAO,2BAA4B,6BAA8B,KAAK,EACtE,OAAO,4BAA6B,6BAA8B,KAAK,EACvE,OAAO,oBAAqB,wBAAyB,EAAK,EAC1D,OAAO,MAAOC,EAASC,IAAY,CAClC,IAAMC,EAASC,EAAW,EACpBC,EAAaC,EAAOH,CAAM,EAE5BD,EAAQ,YACV,MAAMK,EAAgBF,EAAYH,CAAO,EAChCD,EACT,MAAMO,EAAWH,EAAYJ,EAASC,CAAO,GAE7C,QAAQ,IAAIO,EAAM,IAAI,2DAA2D,CAAC,EAClF,QAAQ,KAAK,CAAC,EAElB,CAAC,EAEH,eAAeD,EAAWH,EAAiBJ,EAAiBC,EAAc,CACxE,IAAMQ,EAAUC,EAAI,wBAAwB,EAAE,MAAM,EAEpD,GAAI,CACF,IAAMC,EAAU,CACd,MAAOV,EAAQ,MACf,SAAU,CACR,CAAE,KAAM,OAAQ,QAASD,CAAQ,CACnC,EACA,WAAY,SAASC,EAAQ,SAAS,EACtC,YAAa,WAAWA,EAAQ,WAAW,EAC3C,OAAQA,EAAQ,MAClB,EAEA,GAAIA,EAAQ,OAAQ,CAClBQ,EAAQ,KAAK,EACb,IAAMG,EAAS,MAAMR,EAAW,KAAKO,CAAO,EAE5C,QAAQ,OAAO,MAAMH,EAAM,KAAK,YAAY,CAAC,EAC7C,cAAiBK,KAASD,EACxB,QAAQ,OAAO,MAAMC,CAAK,EAE5B,QAAQ,IAAI,CACd,KAAO,CACL,IAAMC,EAAW,MAAMV,EAAW,KAAKO,CAAO,EAC9CF,EAAQ,KAAK,EAEb,QAAQ,IAAID,EAAM,KAAK,WAAW,CAAC,EACnC,QAAQ,IAAIM,EAAS,QAAQ,CAAC,EAAE,QAAQ,OAAO,CACjD,CACF,OAASC,EAAO,CACdN,EAAQ,KAAK,EACb,QAAQ,MAAMD,EAAM,IAAI,QAAQ,EAAGO,CAAK,EACxC,QAAQ,KAAK,CAAC,CAChB,CACF,CAEA,eAAeT,EAAgBF,EAAiBH,EAAc,CAC5D,QAAQ,IAAIO,EAAM,MAAM,6CAA6C,CAAC,EACtE,QAAQ,IAAIA,EAAM,KAAK,gBAAgBP,EAAQ,KAAK,EAAE,CAAC,EAGvD,IAAMe,EADW,EAAQ,UAAU,EACf,gBAAgB,CAClC,MAAO,QAAQ,MACf,OAAQ,QAAQ,MAClB,CAAC,EAEKC,EAAc,IAAM,CACxBD,EAAG,SAASR,EAAM,KAAK,OAAO,EAAG,MAAOU,GAAkB,CACxD,GAAIA,EAAM,YAAY,IAAM,OAAQ,CAClCF,EAAG,MAAM,EACT,MACF,CAEA,IAAMP,EAAUC,EAAI,wBAAwB,EAAE,MAAM,EAEpD,GAAI,CACF,IAAMC,EAAU,CACd,MAAOV,EAAQ,MACf,SAAU,CACR,CAAE,KAAM,OAAQ,QAASiB,CAAM,CACjC,EACA,WAAY,SAASjB,EAAQ,SAAS,EACtC,YAAa,WAAWA,EAAQ,WAAW,EAC3C,OAAQ,EACV,EAEMa,EAAW,MAAMV,EAAW,KAAKO,CAAO,EAC9CF,EAAQ,KAAK,EAEb,QAAQ,IAAID,EAAM,MAAM,KAAK,EAAGM,EAAS,QAAQ,CAAC,EAAE,QAAQ,OAAO,EACnE,QAAQ,IAAI,EACZG,EAAY,CACd,OAASF,EAAO,CACdN,EAAQ,KAAK,EACb,QAAQ,MAAMD,EAAM,IAAI,QAAQ,EAAGO,CAAK,EACxCE,EAAY,CACd,CACF,CAAC,CACH,EAEAA,EAAY,CACd,CE9GA,OAAS,WAAAE,MAAe,YAExB,OAAOC,MAAW,QAClB,OAAOC,MAAS,MAGT,IAAMC,EAAe,IAAIC,EAAQ,OAAO,EAC5C,YAAY,0BAA0B,EACtC,SAAS,SAAU,eAAe,EAClC,OAAO,sBAAuB,yBAA0B,wCAAwC,EAChG,OAAO,wBAAyB,+BAAgC,MAAM,EACtE,OAAO,kBAAmB,8BAA8B,EACxD,OAAO,MAAOC,EAAMC,IAAY,CAC/B,IAAMC,EAASC,EAAW,EAGpBC,EAAUH,EAAQ,KAAOC,EAAO,UAAYA,EAAO,QAEnDG,EAAaC,EAAO,CAAE,QAAAF,CAAQ,CAAC,EAE/BG,EAAUC,EAAI,yBAAyB,EAAE,MAAM,EAErD,GAAI,CACF,IAAMC,EAAW,MAAMJ,EAAW,MAAM,CACtC,MAAOJ,EAAQ,MACf,MAAOD,CACT,CAAC,EAEDO,EAAQ,KAAK,EAETN,EAAQ,SAAW,UACrB,QAAQ,IAAIS,EAAM,KAAK,mBAAmB,CAAC,EAC3C,QAAQ,IAAID,EAAS,KAAK,CAAC,EAAE,UAAU,MAAM,EAAG,EAAE,EAAE,IAAKE,GAAcA,EAAE,QAAQ,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,EAC/F,QAAQ,IAAID,EAAM,KAAK,QAAQD,EAAS,KAAK,CAAC,EAAE,UAAU,MAAM,cAAc,CAAC,IAE/E,QAAQ,IAAIC,EAAM,KAAK,qBAAqB,CAAC,EAC7C,QAAQ,IAAI,KAAK,UAAUD,EAAU,KAAM,CAAC,CAAC,EAEjD,OAASG,EAAO,CACdL,EAAQ,KAAK,EACb,QAAQ,MAAMG,EAAM,IAAI,QAAQ,EAAGE,CAAK,EACxC,QAAQ,KAAK,CAAC,CAChB,CACF,CAAC,EC3CH,OAAS,WAAAC,MAAe,YAExB,OAAOC,MAAW,QAClB,OAAOC,MAAS,MAChB,UAAYC,MAAQ,KACpB,UAAYC,MAAU,OAGf,IAAMC,EAAe,IAAIC,EAAQ,OAAO,EAC5C,YAAY,mCAAmC,EAC/C,SAAS,WAAY,kCAAkC,EACvD,OAAO,sBAAuB,qBAAsB,0CAA0C,EAC9F,OAAO,oBAAqB,aAAc,WAAW,EACrD,OAAO,0BAA2B,+BAAgC,UAAU,EAC5E,OAAO,wBAAyB,+BAAgC,GAAG,EACnE,OAAO,sBAAuB,kBAAkB,EAChD,OAAO,kBAAmB,0BAA0B,EACpD,OAAO,MAAOC,EAAQC,IAAY,CACjC,IAAMC,EAASC,EAAW,EAGpBC,EAAUH,EAAQ,KAAOC,EAAO,UAAYA,EAAO,QAEnDG,EAAaC,EAAO,CAAE,QAAAF,CAAQ,CAAC,EAE/BG,EAAUC,EAAI,qBAAqB,EAAE,MAAM,EAEjD,GAAI,CACF,IAAMC,EAAW,MAAMJ,EAAW,MAAM,CACtC,MAAOJ,EAAQ,MACf,OAAQD,EACR,KAAMC,EAAQ,KACd,QAASA,EAAQ,QACjB,EAAG,SAASA,EAAQ,MAAM,CAC5B,CAAC,EAEDM,EAAQ,KAAK,EAEb,IAAMG,EAAYD,EAAS,KAAK,CAAC,EACjC,GAAIC,EAAU,SAAU,CACtB,IAAMC,EAAc,OAAO,KAAKD,EAAU,SAAU,QAAQ,EAEtDE,EAAWX,EAAQ,QAAU,mBAAmB,KAAK,IAAI,CAAC,OAC1DY,EAAgB,UAAQD,CAAQ,EAEnC,gBAAcC,EAAUF,CAAW,EAEtC,QAAQ,IAAIG,EAAM,MAAM,sCAAiC,CAAC,EAC1D,QAAQ,IAAIA,EAAM,KAAK,WAAW,EAAGD,CAAQ,EAC7C,QAAQ,IAAIC,EAAM,KAAK,UAAUL,EAAS,KAAK,EAAE,CAAC,EAClD,QAAQ,IAAIK,EAAM,KAAK,SAASb,EAAQ,IAAI,EAAE,CAAC,CACjD,CACF,OAASc,EAAO,CACdR,EAAQ,KAAK,EACb,QAAQ,MAAMO,EAAM,IAAI,QAAQ,EAAGC,CAAK,EACxC,QAAQ,KAAK,CAAC,CAChB,CACF,CAAC,ECzDH,OAAS,WAAAC,MAAe,YACxB,OAAOC,MAAW,QAGX,IAAMC,EAAgB,IAAIC,EAAQ,QAAQ,EAC9C,YAAY,uBAAuB,EACnC,OAAO,oBAAqB,4CAA6C,KAAK,EAC9E,OAAO,MAAOC,GAAY,CACzB,IAAMC,EAASC,EAAW,EAEpBC,EAAS,CACb,KAAM,CACJ,4BACA,2BACA,mCACA,0BACA,sBACA,2BACA,YACF,EACA,MAAO,CACL,yCACA,0CACA,oBACA,mBACA,8DACA,yCACF,EACA,MAAO,CACL,2CACA,iCACA,mCACA,+BACF,CACF,EAEIH,EAAQ,OAAS,OACnB,QAAQ,IAAII,EAAM,KAAK,mBAAmB,CAAC,EAC3C,QAAQ,IAAI,EAEZ,QAAQ,IAAIA,EAAM,MAAM,yBAAyB,CAAC,EAClDD,EAAO,KAAK,QAAQE,GAAS,CAC3B,QAAQ,IAAI,KAAKD,EAAM,KAAK,QAAG,CAAC,IAAIC,CAAK,EAAE,CAC7C,CAAC,EAED,QAAQ,IAAI,EACZ,QAAQ,IAAID,EAAM,MAAM,mBAAmB,CAAC,EAC5CD,EAAO,MAAM,QAAQE,GAAS,CAC5B,QAAQ,IAAI,KAAKD,EAAM,KAAK,QAAG,CAAC,IAAIC,CAAK,EAAE,CAC7C,CAAC,EAED,QAAQ,IAAI,EACZ,QAAQ,IAAID,EAAM,MAAM,0BAA0B,CAAC,EACnDD,EAAO,MAAM,QAAQE,GAAS,CAC5B,QAAQ,IAAI,KAAKD,EAAM,KAAK,QAAG,CAAC,IAAIC,CAAK,EAAE,CAC7C,CAAC,GACQF,EAAOH,EAAQ,IAA2B,GACnD,QAAQ,IAAII,EAAM,KAAK,GAAGJ,EAAQ,KAAK,OAAO,CAAC,EAAE,YAAY,EAAIA,EAAQ,KAAK,MAAM,CAAC,CAAC,UAAU,CAAC,EACjGG,EAAOH,EAAQ,IAA2B,EAAE,QAAQK,GAAS,CAC3D,QAAQ,IAAI,KAAKD,EAAM,KAAK,QAAG,CAAC,IAAIC,CAAK,EAAE,CAC7C,CAAC,IAED,QAAQ,IAAID,EAAM,IAAI,4DAA4D,CAAC,EACnF,QAAQ,KAAK,CAAC,EAElB,CAAC,ECjEH,OAAS,WAAAE,MAAe,YACxB,OAAOC,MAAW,QAClB,UAAYC,MAAQ,KACpB,UAAYC,MAAU,OACtB,UAAYC,MAAQ,KAEb,IAAMC,EAAgB,IAAIL,EAAQ,QAAQ,EAC9C,YAAY,iCAAiC,EAC7C,QAAQ,KAAK,EACb,YAAY,0BAA0B,EACtC,SAAS,QAAS,6DAA6D,EAC/E,SAAS,UAAW,qBAAqB,EACzC,OAAO,MAAOM,EAAKC,IAAU,CAC5B,IAAMC,EAAkB,OAAQ,UAAQ,EAAG,cAAe,aAAa,EACjEC,EAAiB,UAAQD,CAAU,EAGjC,aAAWC,CAAS,GACvB,YAAUA,EAAW,CAAE,UAAW,EAAK,CAAC,EAI7C,IAAIC,EAAc,CAAC,EACnB,GAAO,aAAWF,CAAU,EAC1B,GAAI,CACFE,EAAS,KAAK,MAAS,eAAaF,EAAY,MAAM,CAAC,CACzD,MAAgB,CACd,QAAQ,IAAIP,EAAM,OAAO,2DAA2D,CAAC,CACvF,CAIFS,EAAOJ,CAAG,EAAIC,EAGX,gBAAcC,EAAY,KAAK,UAAUE,EAAQ,KAAM,CAAC,CAAC,EAE5D,QAAQ,IAAIT,EAAM,MAAM,cAASK,CAAG,MAAMC,CAAK,EAAE,CAAC,CACpD,CAAC,EAEHF,EACG,QAAQ,KAAK,EACb,YAAY,0BAA0B,EACtC,SAAS,QAAS,qCAAqC,EACvD,OAAO,MAAOC,GAAQ,CACrB,IAAMI,EAASC,EAAW,EAEtBL,EACEI,EAAOJ,CAAG,EACZ,QAAQ,IAAIL,EAAM,KAAK,GAAGK,CAAG,GAAG,EAAGI,EAAOJ,CAAG,CAAC,GAE9C,QAAQ,IAAIL,EAAM,IAAI,sBAAsBK,CAAG,aAAa,CAAC,EAC7D,QAAQ,KAAK,CAAC,IAGhB,QAAQ,IAAIL,EAAM,KAAK,wBAAwB,CAAC,EAChD,OAAO,QAAQS,CAAM,EAAE,QAAQ,CAAC,CAACE,EAAGC,CAAC,IAAM,CACzC,QAAQ,IAAI,KAAKZ,EAAM,KAAKW,CAAC,CAAC,KAAKC,CAAC,EAAE,CACxC,CAAC,EAEL,CAAC,EAEHR,EACG,QAAQ,MAAM,EACd,YAAY,+BAA+B,EAC3C,OAAO,SAAY,CAClB,IAAMK,EAASC,EAAW,EAE1B,QAAQ,IAAIV,EAAM,KAAK,wBAAwB,CAAC,EAChD,OAAO,QAAQS,CAAM,EAAE,QAAQ,CAAC,CAACE,EAAGC,CAAC,IAAM,CACzC,QAAQ,IAAI,KAAKZ,EAAM,KAAKW,CAAC,CAAC,KAAKC,CAAC,EAAE,CACxC,CAAC,CACH,CAAC,EAEI,SAASF,GAAkB,CAChC,IAAMH,EAAkB,OAAQ,UAAQ,EAAG,cAAe,aAAa,EAEvE,GAAI,CAAI,aAAWA,CAAU,EAC3B,MAAO,CACL,QAAS,0BACX,EAGF,GAAI,CACF,OAAO,KAAK,MAAS,eAAaA,EAAY,MAAM,CAAC,CACvD,MAAgB,CACd,eAAQ,IAAIP,EAAM,OAAO,qDAAqD,CAAC,EACxE,CACL,QAAS,0BACX,CACF,CACF,CNlFA,IAAMa,EAAU,IAAIC,EAEpBD,EACG,KAAK,YAAY,EACjB,YAAY,gDAAgD,EAC5D,QAAQ,OAAO,EAGlBA,EAAQ,WAAWE,CAAW,EAC9BF,EAAQ,WAAWG,CAAY,EAC/BH,EAAQ,WAAWI,CAAY,EAC/BJ,EAAQ,WAAWK,CAAa,EAChCL,EAAQ,WAAWM,CAAa,EAEhCN,EAAQ,MAAM","names":["Command","Command","chalk","ora","fs","path","os","readConfig","configPath","config","chatCommand","Command","message","options","config","readConfig","openmodels","client","interactiveChat","singleChat","chalk","spinner","ora","request","stream","token","response","error","rl","askQuestion","input","Command","chalk","ora","embedCommand","Command","text","options","config","readConfig","baseUrl","openmodels","client","spinner","ora","response","chalk","v","error","Command","chalk","ora","fs","path","imageCommand","Command","prompt","options","config","readConfig","baseUrl","openmodels","client","spinner","ora","response","imageData","imageBuffer","filename","filepath","chalk","error","Command","chalk","modelsCommand","Command","options","config","readConfig","models","chalk","model","Command","chalk","fs","path","os","configCommand","key","value","configPath","configDir","config","readConfig","k","v","program","Command","chatCommand","embedCommand","imageCommand","modelsCommand","configCommand"]}